### YamlMime:ManagedReference
items:
- uid: System.Speech.Recognition.SpeechRecognizer
  id: SpeechRecognizer
  children:
  - System.Speech.Recognition.SpeechRecognizer.#ctor
  - System.Speech.Recognition.SpeechRecognizer.AudioFormat
  - System.Speech.Recognition.SpeechRecognizer.AudioLevel
  - System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated
  - System.Speech.Recognition.SpeechRecognizer.AudioPosition
  - System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred
  - System.Speech.Recognition.SpeechRecognizer.AudioState
  - System.Speech.Recognition.SpeechRecognizer.AudioStateChanged
  - System.Speech.Recognition.SpeechRecognizer.Dispose
  - System.Speech.Recognition.SpeechRecognizer.Dispose(System.Boolean)
  - System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)
  - System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  - System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)
  - System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)
  - System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  - System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)
  - System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted
  - System.Speech.Recognition.SpeechRecognizer.Enabled
  - System.Speech.Recognition.SpeechRecognizer.Grammars
  - System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)
  - System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)
  - System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted
  - System.Speech.Recognition.SpeechRecognizer.MaxAlternates
  - System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition
  - System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition
  - System.Speech.Recognition.SpeechRecognizer.RecognizerInfo
  - System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached
  - System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate
  - System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object)
  - System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object,System.TimeSpan)
  - System.Speech.Recognition.SpeechRecognizer.SpeechDetected
  - System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized
  - System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected
  - System.Speech.Recognition.SpeechRecognizer.SpeechRecognized
  - System.Speech.Recognition.SpeechRecognizer.State
  - System.Speech.Recognition.SpeechRecognizer.StateChanged
  - System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars
  - System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)
  langs:
  - csharp
  name: SpeechRecognizer
  nameWithType: SpeechRecognizer
  fullName: System.Speech.Recognition.SpeechRecognizer
  type: Class
  summary: "在 Windows 桌面上提供对中提供的共享的语音识别服务访问。"
  remarks: "应用程序使用共享识别器访问 Windows 语音识别。 使用 SpeechRecognizer 对象将添加到 Windows 语音用户体验。       此类提供了对语音识别过程的各个方面控制:-若要将管理语音识别语法，请使用<xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A>， <xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A>， <xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A>， <xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A>，和<xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A>。</xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A> </xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A> </xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A> </xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A> </xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A>      -若要获取有关当前语音信息识别操作，订阅 SpeechRecognizer <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>， <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>， <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>，和<xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized>事件。</xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> </xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected> </xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized> </xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>      -若要查看或修改的备用识别器返回的结果数，请使用<xref:System.Speech.Recognition.SpeechRecognizer.MaxAlternates%2A>属性。</xref:System.Speech.Recognition.SpeechRecognizer.MaxAlternates%2A> 识别器返回识别导致<xref:System.Speech.Recognition.RecognitionResult>对象。</xref:System.Speech.Recognition.RecognitionResult>      -若要访问或监视共享识别器的状态，使用<xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A>， <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>， <xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A>， <xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A>， <xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A>， <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>，和<xref:System.Speech.Recognition.SpeechRecognizer.State%2A>属性和<xref:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated>， <xref:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred>， <xref:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged>，和<xref:System.Speech.Recognition.SpeechRecognizer.StateChanged>事件。</xref:System.Speech.Recognition.SpeechRecognizer.StateChanged> </xref:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged> </xref:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred> </xref:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated> </xref:System.Speech.Recognition.SpeechRecognizer.State%2A> </xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A> </xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A> </xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A> </xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A> </xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A> </xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A>      -若要将更改同步到识别器，使用<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>方法。</xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> 共享识别器使用多个线程来执行任务。      -若要模拟共享识别的输入，使用<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A>和<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>方法。</xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> </xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A>       通过使用管理的 Windows 语音识别的配置**语音属性**中的对话框**控制面板**。 此接口用于选择默认桌面语音识别引擎和语言、 音频输入的设备，以及语音识别睡眠行为。 如果 Windows 语音识别的配置更改 （例如，如果语音识别被禁用，或更改的输入的语言） 运行应用程序时，此更改将影响所有 SpeechRecognizer 对象。       若要创建独立于 Windows 语音识别进程内语音识别器，使用<xref:System.Speech.Recognition.SpeechRecognitionEngine>类。</xref:System.Speech.Recognition.SpeechRecognitionEngine>      1> [!NOTE]&1;> 始终调用<xref:System.Speech.Recognition.SpeechRecognizer.Dispose%2A>在发布到语音识别器最后一个引用之前。</xref:System.Speech.Recognition.SpeechRecognizer.Dispose%2A> 否则，它所使用的资源不会被释放之前垃圾回收器调用识别器对象的`Finalize`方法。"
  example:
  - "The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer.  If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition. If Windows Speech Recognition is in the **Sleeping** state, then <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> always returns null.  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace SharedRecognizer  \n{  \n  class Program  \n  {  \n  \n    // Indicate whether the asynchronous emulate recognition  \n    // operation has completed.  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n    {  \n  \n      // Initialize an instance of the shared recognizer.  \n      using (SpeechRecognizer recognizer = new SpeechRecognizer())  \n      {  \n  \n        // Create and load a sample grammar.  \n        Grammar testGrammar =  \n          new Grammar(new GrammarBuilder(\"testing testing\"));  \n        testGrammar.Name = \"Test Grammar\";  \n        recognizer.LoadGrammar(testGrammar);  \n  \n        // Attach event handlers for recognition events.  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(  \n            SpeechRecognizedHandler);  \n        recognizer.EmulateRecognizeCompleted +=  \n          new EventHandler<EmulateRecognizeCompletedEventArgs>(  \n            EmulateRecognizeCompletedHandler);  \n  \n        completed = false;  \n  \n        // Start asynchronous emulated recognition.   \n        // This matches the grammar and generates a SpeechRecognized event.  \n        recognizer.EmulateRecognizeAsync(\"testing testing\");  \n  \n        // Wait for the asynchronous operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n  \n        completed = false;  \n  \n        // Start asynchronous emulated recognition.  \n        // This does not match the grammar or generate a SpeechRecognized event.  \n        recognizer.EmulateRecognizeAsync(\"testing one two three\");  \n  \n        // Wait for the asynchronous operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(\"Recognition result = {0}\",  \n          e.Result.Text ?? \"<no text>\");  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"No recognition result\");  \n      }  \n    }  \n  \n    // Handle the SpeechRecognizeCompleted event.  \n    static void EmulateRecognizeCompletedHandler(  \n      object sender, EmulateRecognizeCompletedEventArgs e)  \n    {  \n      if (e.Result == null)  \n      {  \n        Console.WriteLine(\"No result generated.\");  \n      }  \n  \n      // Indicate the asynchronous operation is complete.  \n      completed = true;  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: 'public class SpeechRecognizer : IDisposable'
  inheritance:
  - System.Object
  implements:
  - System.IDisposable
  inheritedMembers: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.#ctor
  id: '#ctor'
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: SpeechRecognizer()
  nameWithType: SpeechRecognizer.SpeechRecognizer()
  fullName: System.Speech.Recognition.SpeechRecognizer.SpeechRecognizer()
  type: Constructor
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "初始化的新实例<xref href=&quot;System.Speech.Recognition.SpeechRecognizer&quot;></xref>类。"
  remarks: "每个<xref:System.Speech.Recognition.SpeechRecognizer>对象维护一组单独的语音识别语法。</xref:System.Speech.Recognition.SpeechRecognizer>"
  example:
  - "The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer. If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition. If Windows Speech Recognition is in the **Sleeping** state, then <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> always returns null.  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace SharedRecognizer  \n{  \n  class Program  \n  {  \n  \n    // Indicate whether the asynchronous emulate recognition  \n    // operation has completed.  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n    {  \n  \n      // Initialize an instance of the shared recognizer.  \n      using (SpeechRecognizer recognizer = new SpeechRecognizer())  \n      {  \n  \n        // Create and load a sample grammar.  \n        Grammar testGrammar =  \n          new Grammar(new GrammarBuilder(\"testing testing\"));  \n        testGrammar.Name = \"Test Grammar\";  \n        recognizer.LoadGrammar(testGrammar);  \n  \n        // Attach event handlers for recognition events.  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(  \n            SpeechRecognizedHandler);  \n        recognizer.EmulateRecognizeCompleted +=  \n          new EventHandler<EmulateRecognizeCompletedEventArgs>(  \n            EmulateRecognizeCompletedHandler);  \n  \n        completed = false;  \n  \n        // Start asynchronous emulated recognition.   \n        // This matches the grammar and generates a SpeechRecognized event.  \n        recognizer.EmulateRecognizeAsync(\"testing testing\");  \n  \n        // Wait for the asynchronous operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n  \n        completed = false;  \n  \n        // Start asynchronous emulated recognition.  \n        // This does not match the grammar or generate a SpeechRecognized event.  \n        recognizer.EmulateRecognizeAsync(\"testing one two three\");  \n  \n        // Wait for the asynchronous operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(\"Recognition result = {0}\",  \n          e.Result.Text ?? \"<no text>\");  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"No recognition result\");  \n      }  \n    }  \n  \n    // Handle the SpeechRecognizeCompleted event.  \n    static void EmulateRecognizeCompletedHandler(  \n      object sender, EmulateRecognizeCompletedEventArgs e)  \n    {  \n      if (e.Result == null)  \n      {  \n        Console.WriteLine(\"No result generated.\");  \n      }  \n  \n      // Indicate the asynchronous operation is complete.  \n      completed = true;  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public SpeechRecognizer ();
    parameters: []
  overload: System.Speech.Recognition.SpeechRecognizer.#ctor*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.AudioFormat
  id: AudioFormat
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: AudioFormat
  nameWithType: SpeechRecognizer.AudioFormat
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioFormat
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "获取语音识别器接收的音频格式。"
  syntax:
    content: public System.Speech.AudioFormat.SpeechAudioFormatInfo AudioFormat { get; }
    return:
      type: System.Speech.AudioFormat.SpeechAudioFormatInfo
      description: "语音识别器，音频输入的格式或<xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;></xref>如果未配置到识别器输入。"
  overload: System.Speech.Recognition.SpeechRecognizer.AudioFormat*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.AudioLevel
  id: AudioLevel
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: AudioLevel
  nameWithType: SpeechRecognizer.AudioLevel
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioLevel
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "获取语音识别器接收的音频的级别。"
  syntax:
    content: public int AudioLevel { get; }
    return:
      type: System.Int32
      description: "语音识别器，从 0 到 100 的输入音频级别。"
  overload: System.Speech.Recognition.SpeechRecognizer.AudioLevel*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated
  id: AudioLevelUpdated
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: AudioLevelUpdated
  nameWithType: SpeechRecognizer.AudioLevelUpdated
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "共享识别器报告的级别其音频输入时发生。"
  remarks: "识别器引发多个时间每秒此事件。 与引发事件的频率取决于在其运行应用程序的计算机。       若要在事件的时间获取音频级别，使用<xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs.AudioLevel%2A>的关联<xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs>。</xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs>属性</xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs.AudioLevel%2A> 若要获取识别器的输入的当前音频级别，使用识别器<xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A>属性。</xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A>       当你创建的委托`AudioLevelUpdated`事件，需要标识将处理该事件的方法。 若要将事件与事件处理程序关联，添加到事件的委托的一个实例。 除非移除了该委托，称为每当发生该事件时，事件处理程序。 有关事件处理程序委托的详细信息，请参阅[事件和委托](http://go.microsoft.com/fwlink/?LinkId=162418)。"
  example:
  - "The following example adds a handler for the `AudioLevelUpdated` event to a <xref:System.Speech.Recognition.SpeechRecognizer> object. The handler outputs the new audio level to the console.  \n  \n```c#  \nprivate SpeechRecognizer recognizer;  \n  \n// Initialize the SpeechRecognizer object.   \nprivate void Initialize()  \n{  \n  recognizer = new SpeechRecognizer();  \n  \n  // Add an event handler for the AudioLevelUpdated event.  \n  recognizer.AudioLevelUpdated +=   \n    new EventHandler<AudioLevelUpdatedEventArgs>(recognizer_AudioLevelUpdated);  \n  \n  // Add other initialization code here.  \n  \n}  \n  \n// Write the audio level to the console when the AudioLevelUpdated event is raised.  \nvoid recognizer_AudioLevelUpdated(object sender, AudioLevelUpdatedEventArgs e)  \n{  \n  Console.WriteLine(\"The audio level is now: {0}.\", e.AudioLevel);  \n}  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.AudioLevelUpdatedEventArgs> AudioLevelUpdated;
    return:
      type: System.EventHandler{System.Speech.Recognition.AudioLevelUpdatedEventArgs}
      description: "要添加。"
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.AudioPosition
  id: AudioPosition
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: AudioPosition
  nameWithType: SpeechRecognizer.AudioPosition
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioPosition
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "获取当前正在生成的语音识别器的输入提供的设备的音频流中的位置。"
  remarks: "桌面语音识别正在运行时，共享识别器收到输入。       `AudioPosition`属性引用在其生成的音频流中的输入的设备的位置。 与此相反，<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>属性引用音频输入处理识别器的位置。</xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A> 这些位置可以是不同的。  例如，如果收到识别器输入其具有不但生成识别结果则的值<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>属性小于 AudioPosition 属性的值。</xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>"
  example:
  - "In the following example, the shared speech recognizer uses a dictation grammar to match speech input. A handler for the <xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected> event writes to the console the AudioPosition, <xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>, and  <xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A> when the speech recognizer detects speech at its input.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    private static SpeechRecognizer recognizer;  \n    public static void Main(string[] args)  \n    {  \n  \n      // Initialize a shared speech recognition engine.  \n      recognizer = new SpeechRecognizer();  \n  \n      // Add handlers for events.  \n      recognizer.LoadGrammarCompleted +=   \n        new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n      recognizer.SpeechRecognized +=   \n        new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n      recognizer.StateChanged +=   \n        new EventHandler<StateChangedEventArgs>(recognizer_StateChanged);  \n      recognizer.SpeechDetected +=   \n        new EventHandler<SpeechDetectedEventArgs>(recognizer_SpeechDetected);  \n  \n      // Create a dictation grammar.  \n      Grammar dictation = new DictationGrammar();  \n      dictation.Name = \"Dictation\";  \n  \n      // Load the grammar object to the recognizer.  \n      recognizer.LoadGrammarAsync(dictation);  \n  \n      // Keep the console window open.  \n      Console.ReadLine();  \n    }  \n  \n    // Gather information about detected speech and write it to the console.  \n    static void recognizer_SpeechDetected(object sender, SpeechDetectedEventArgs e)  \n    {  \n      Console.WriteLine();  \n      Console.WriteLine(\"Speech detected:\");  \n      Console.WriteLine(\"  Audio level: \" + recognizer.AudioLevel);  \n      Console.WriteLine(\"  Audio position: \" + recognizer.AudioPosition);  \n      Console.WriteLine(\"  Recognizer audio position: \" + recognizer.RecognizerAudioPosition);  \n    }  \n  \n    // Write the text of the recognition result to the console.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {   \n      Console.WriteLine(\"Speech recognized: \" + e.Result.Text);  \n  \n      // Add event handler code here.  \n    }  \n  \n    // Write the name of the loaded grammar to the console.  \n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"Grammar loaded: \" + e.Grammar.Name);  \n    }  \n  \n    // Put the shared speech recognizer into \"listening\" mode.  \n    static void recognizer_StateChanged(object sender, StateChangedEventArgs e)  \n    {  \n      if (e.RecognizerState != RecognizerState.Stopped)  \n      {  \n        recognizer.EmulateRecognizeAsync(\"Start listening\");  \n      }  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public TimeSpan AudioPosition { get; }
    return:
      type: System.TimeSpan
      description: "当前的语音识别器已通过其接收到输入音频的输入流中的位置。"
  overload: System.Speech.Recognition.SpeechRecognizer.AudioPosition*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred
  id: AudioSignalProblemOccurred
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: AudioSignalProblemOccurred
  nameWithType: SpeechRecognizer.AudioSignalProblemOccurred
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "当识别器遇到音频信号中的问题时发生。"
  remarks: "若要获取出现的问题，请使用<xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem%2A>关联<xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs>。</xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs>属性</xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem%2A>       当你创建的委托`AudioSignalProblemOccurred`事件，需要标识将处理该事件的方法。 若要将事件与事件处理程序关联，添加到事件的委托的一个实例。 除非移除了该委托，称为每当发生该事件时，事件处理程序。 有关事件处理程序委托的详细信息，请参阅[事件和委托](http://go.microsoft.com/fwlink/?LinkId=162418)。"
  example:
  - "The following example defines an event handler that gathers information about an `AudioSignalProblemOccurred` event.  \n  \n```  \nprivate SpeechRecognizer recognizer;  \n  \n// Initialize the speech recognition engine.  \nprivate void Initialize()  \n{  \n  recognizer = new SpeechRecognizer();  \n  \n  // Add a handler for the AudioSignalProblemOccurred event.  \n  recognizer.AudioSignalProblemOccurred +=   \n    new EventHandler<AudioSignalProblemOccurredEventArgs>(  \n      recognizer_AudioSignalProblemOccurred);  \n}  \n  \n// Gather information when the AudioSignalProblemOccurred event is raised.  \nvoid recognizer_AudioSignalProblemOccurred(object sender, AudioSignalProblemOccurredEventArgs e)  \n{  \n  StringBuilder details = new StringBuilder();  \n  \n  details.AppendLine(\"Audio signal problem information:\");  \n  details.AppendFormat(  \n    \" Audio level:               {0}\" + Environment.NewLine +  \n    \" Audio position:            {1}\" + Environment.NewLine +  \n    \" Audio signal problem:      {2}\" + Environment.NewLine +  \n    \" Recognition engine audio position: {3}\" + Environment.NewLine,  \n    e.AudioLevel, e.AudioPosition,  e.AudioSignalProblem,  \n    e.recoEngineAudioPosition);  \n  \n  // Insert additional event handler code here.  \n}  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.AudioSignalProblemOccurredEventArgs> AudioSignalProblemOccurred;
    return:
      type: System.EventHandler{System.Speech.Recognition.AudioSignalProblemOccurredEventArgs}
      description: "要添加。"
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.AudioState
  id: AudioState
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: AudioState
  nameWithType: SpeechRecognizer.AudioState
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioState
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "获取语音识别器接收的音频的状态。"
  syntax:
    content: public System.Speech.Recognition.AudioState AudioState { get; }
    return:
      type: System.Speech.Recognition.AudioState
      description: "语音识别器的音频输入状态。"
  overload: System.Speech.Recognition.SpeechRecognizer.AudioState*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.AudioStateChanged
  id: AudioStateChanged
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: AudioStateChanged
  nameWithType: SpeechRecognizer.AudioStateChanged
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioStateChanged
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "识别器接收音频中的状态更改时发生。"
  remarks: "若要在事件的时间获取音频的状态，使用<xref:System.Speech.Recognition.AudioStateChangedEventArgs.AudioState%2A>的关联<xref:System.Speech.Recognition.AudioStateChangedEventArgs>。</xref:System.Speech.Recognition.AudioStateChangedEventArgs>属性</xref:System.Speech.Recognition.AudioStateChangedEventArgs.AudioState%2A> 若要获取识别器的输入音频的当前状态，请使用识别器<xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A>属性。</xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A> 有关 audio 状态的详细信息，请参阅<xref:System.Speech.Recognition.AudioState>枚举。</xref:System.Speech.Recognition.AudioState>       当你创建的委托`AudioStateChanged`事件，需要标识将处理该事件的方法。 若要将事件与事件处理程序关联，添加到事件的委托的一个实例。 除非移除了该委托，称为每当发生该事件时，事件处理程序。 有关事件处理程序委托的详细信息，请参阅[事件和委托](http://go.microsoft.com/fwlink/?LinkId=162418)。"
  example:
  - "The following example uses a handler for the `AudioStateChanged` event to write the recognizer's new <xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A> to the console each time it changes using a member of the <xref:System.Speech.Recognition.AudioState> enumeration.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    private static SpeechRecognizer recognizer;  \n    public static void Main(string[] args)  \n    {  \n  \n      // Initialize a shared speech recognition engine.  \n      recognizer = new SpeechRecognizer();  \n  \n        // Create and load a grammar.  \n        Grammar dictation = new DictationGrammar();  \n        dictation.Name = \"Dictation Grammar\";  \n        recognizer.LoadGrammar(dictation);  \n  \n        // Attach event handlers.  \n        recognizer.AudioStateChanged +=  \n          new EventHandler<AudioStateChangedEventArgs>(recognizer_AudioStateChanged);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n        recognizer.StateChanged +=  \n          new EventHandler<StateChangedEventArgs>(recognizer_StateChanged);  \n  \n        // Keep the console window open.  \n        Console.ReadLine();  \n      }  \n  \n    // Handle the AudioStateChanged event.  \n    static void recognizer_AudioStateChanged(object sender, AudioStateChangedEventArgs e)  \n    {  \n      Console.WriteLine(\"The new audio state is: \" + e.AudioState);  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      if (e.Result != null && e.Result.Text != null)  \n      {  \n        Console.WriteLine();  \n        Console.WriteLine(\"  Recognized text =  {0}\", e.Result.Text);  \n        Console.WriteLine();  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"  Recognized text not available.\");  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Done.\");  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Put the recognizer into Listening mode.  \n    static void recognizer_StateChanged(object sender, StateChangedEventArgs e)  \n    {  \n      if (e.RecognizerState != RecognizerState.Stopped)  \n      {  \n        Console.WriteLine();  \n        recognizer.EmulateRecognizeAsync(\"Start listening\");  \n      }  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.AudioStateChangedEventArgs> AudioStateChanged;
    return:
      type: System.EventHandler{System.Speech.Recognition.AudioStateChangedEventArgs}
      description: "要添加。"
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.Dispose
  id: Dispose
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: Dispose()
  nameWithType: SpeechRecognizer.Dispose()
  fullName: System.Speech.Recognition.SpeechRecognizer.Dispose()
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "释放<xref href=&quot;System.Speech.Recognition.SpeechRecognizer&quot;></xref>对象。"
  syntax:
    content: public void Dispose ();
    parameters: []
  overload: System.Speech.Recognition.SpeechRecognizer.Dispose*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.Dispose(System.Boolean)
  id: Dispose(System.Boolean)
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: Dispose(Boolean)
  nameWithType: SpeechRecognizer.Dispose(Boolean)
  fullName: System.Speech.Recognition.SpeechRecognizer.Dispose(Boolean)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "释放<xref href=&quot;System.Speech.Recognition.SpeechRecognizer&quot;></xref>在会话期间使用的对象并释放资源。"
  syntax:
    content: protected virtual void Dispose (bool disposing);
    parameters:
    - id: disposing
      type: System.Boolean
      description: "<xref uid=&quot;langword_csharp_true&quot; name=&quot;true&quot; href=&quot;&quot;></xref>若要释放托管和非托管资源;<xref uid=&quot;langword_csharp_false&quot; name=&quot;false&quot; href=&quot;&quot;> </xref>若要仅释放非托管的资源。"
  overload: System.Speech.Recognition.SpeechRecognizer.Dispose*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)
  id: EmulateRecognize(System.String)
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: EmulateRecognize(String)
  nameWithType: SpeechRecognizer.EmulateRecognize(String)
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(String)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "模拟的短语共享的语音识别器，使用文本而不音频进行同步的语音识别的输入。"
  remarks: "附带 Vista 和 Windows 7 的识别器忽略大小写和字符宽度时将语法规则应用于输入的短语。 有关这种比较类型的详细信息，请参阅<xref:System.Globalization.CompareOptions>枚举值<xref:System.Globalization.CompareOptions>和<xref:System.Globalization.CompareOptions>。</xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> 识别器还忽略新行和额外的空白区域，并将标点作为文本输入。"
  example:
  - "The following example loads a sample grammar to the shared recognizer and emulates input to the recognizer. If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition. If Windows Speech Recognition is in the **Sleeping** state, then <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A> always returns null.  \n  \n```c#  \n  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SharedRecognizer  \n{  \n  class Program  \n  {  \n  \n    static void Main(string[] args)  \n    {  \n      // Initialize an instance of the shared recognizer.  \n      using (SpeechRecognizer recognizer = new SpeechRecognizer())  \n      {  \n        // Create and load a sample grammar.  \n        Grammar testGrammar =  \n          new Grammar(new GrammarBuilder(\"testing testing\"));  \n        testGrammar.Name = \"Test Grammar\";  \n  \n        recognizer.LoadGrammar(testGrammar);  \n  \n        RecognitionResult result;  \n  \n        // This EmulateRecognize call matches the grammar and returns a  \n        // recognition result.  \n        result = recognizer.EmulateRecognize(\"testing testing\");  \n        OutputResult(result);  \n  \n        // This EmulateRecognize call does not match the grammar and   \n        // returns null.  \n        result = recognizer.EmulateRecognize(\"testing one two three\");  \n        OutputResult(result);  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Output information about a recognition result to the console.  \n    private static void OutputResult(RecognitionResult result)  \n    {  \n      if (result != null)  \n      {  \n        Console.WriteLine(\"Recognition result = {0}\",  \n          result.Text ?? \"<no text>\");  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"No recognition result\");  \n      }  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public System.Speech.Recognition.RecognitionResult EmulateRecognize (string inputText);
    parameters:
    - id: inputText
      type: System.String
      description: "识别操作输入。"
    return:
      type: System.Speech.Recognition.RecognitionResult
      description: "识别的操作，识别结果或<xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;> </xref>，如果该操作未成功或 Windows 语音识别出现**休眠**状态。"
  overload: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  id: EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: EmulateRecognize(RecognizedWordUnit[],CompareOptions)
  nameWithType: SpeechRecognizer.EmulateRecognize(RecognizedWordUnit[],CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(RecognizedWordUnit[],CompareOptions)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "模拟特定单词的共享的语音识别器，使用文本而不音频进行同步的语音识别的输入，并指定在识别器处理 Unicode 比较单词和加载的语音识别语法的方式。"
  remarks: "此方法创建<xref:System.Speech.Recognition.RecognitionResult>对象使用中提供的信息`wordUnits`参数。</xref:System.Speech.Recognition.RecognitionResult>       识别器使用`compareOptions`当它将语法规则应用于输入的短语。 附带 Vista 和 Windows 7 的识别器忽略大小写，如果<xref:System.Globalization.CompareOptions>或<xref:System.Globalization.CompareOptions>值是否存在。</xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> 识别器始终忽略字符宽度和永远不会忽略假名类型。 识别器还忽略新行和额外的空白区域，并将标点作为文本输入。 有关字符宽度和假名类型的详细信息，请参阅<xref:System.Globalization.CompareOptions>枚举。</xref:System.Globalization.CompareOptions>"
  syntax:
    content: public System.Speech.Recognition.RecognitionResult EmulateRecognize (System.Speech.Recognition.RecognizedWordUnit[] wordUnits, System.Globalization.CompareOptions compareOptions);
    parameters:
    - id: wordUnits
      type: System.Speech.Recognition.RecognizedWordUnit[]
      description: "包含有关识别操作的输入 word 单位的数组。"
    - id: compareOptions
      type: System.Globalization.CompareOptions
      description: "描述要用于模拟的识别操作的比较类型的枚举值的按位组合。"
    return:
      type: System.Speech.Recognition.RecognitionResult
      description: "识别的操作，识别结果或<xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;> </xref>，如果该操作未成功或 Windows 语音识别出现**休眠**状态。"
  overload: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)
  id: EmulateRecognize(System.String,System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: EmulateRecognize(String,CompareOptions)
  nameWithType: SpeechRecognizer.EmulateRecognize(String,CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(String,CompareOptions)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "模拟的短语共享的语音识别器，使用文本而不音频进行同步的语音识别的输入，并指定如何识别器处理 Unicode 短语和加载的语音识别语法之间的比较。"
  remarks: "识别器使用`compareOptions`当它将语法规则应用于输入的短语。 附带 Vista 和 Windows 7 的识别器忽略大小写，如果<xref:System.Globalization.CompareOptions>或<xref:System.Globalization.CompareOptions>值是否存在。</xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> 识别器始终忽略字符宽度和永远不会忽略假名类型。 识别器还忽略新行和额外的空白区域，并将标点作为文本输入。 有关字符宽度和假名类型的详细信息，请参阅<xref:System.Globalization.CompareOptions>枚举。</xref:System.Globalization.CompareOptions>"
  syntax:
    content: public System.Speech.Recognition.RecognitionResult EmulateRecognize (string inputText, System.Globalization.CompareOptions compareOptions);
    parameters:
    - id: inputText
      type: System.String
      description: "识别操作输入的短语。"
    - id: compareOptions
      type: System.Globalization.CompareOptions
      description: "描述要用于模拟的识别操作的比较类型的枚举值的按位组合。"
    return:
      type: System.Speech.Recognition.RecognitionResult
      description: "识别的操作，识别结果或<xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;> </xref>，如果该操作未成功或 Windows 语音识别出现**休眠**状态。"
  overload: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)
  id: EmulateRecognizeAsync(System.String)
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: EmulateRecognizeAsync(String)
  nameWithType: SpeechRecognizer.EmulateRecognizeAsync(String)
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(String)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "模拟的短语共享的语音识别器，而不音频的文本用于异步语音识别的输入。"
  remarks: "附带 Vista 和 Windows 7 的识别器忽略大小写和字符宽度时将语法规则应用于输入的短语。 有关这种比较类型的详细信息，请参阅<xref:System.Globalization.CompareOptions>枚举值<xref:System.Globalization.CompareOptions>和<xref:System.Globalization.CompareOptions>。</xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> 识别器还忽略新行和额外的空白区域，并将标点作为文本输入。"
  example:
  - "The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer. If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition. If Windows Speech Recognition is in the **Sleeping** state, then <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> always returns null.  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace SharedRecognizer  \n{  \n  class Program  \n  {  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n    {  \n      // Initialize an instance of the shared recognizer.  \n      using (SpeechRecognizer recognizer = new SpeechRecognizer())  \n      {  \n        // Create and load a sample grammar.  \n        Grammar testGrammar =  \n          new Grammar(new GrammarBuilder(\"testing testing\"));  \n        testGrammar.Name = \"Test Grammar\";  \n  \n        recognizer.LoadGrammar(testGrammar);  \n  \n        // Attach event handlers for recognition events.  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(  \n            SpeechRecognizedHandler);  \n        recognizer.EmulateRecognizeCompleted +=  \n          new EventHandler<EmulateRecognizeCompletedEventArgs>(  \n            EmulateRecognizeCompletedHandler);  \n  \n        completed = false;  \n  \n        // This EmulateRecognizeAsync call generates a SpeechRecognized event.  \n        recognizer.EmulateRecognizeAsync(\"testing testing\");  \n  \n        // Wait for the asynchronous operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n  \n        completed = false;  \n  \n        // This EmulateRecognizeAsync call does not match the grammar   \n        // or generate a SpeechRecognized event.  \n        recognizer.EmulateRecognizeAsync(\"testing one two three\");  \n  \n        // Wait for the asynchronous operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(\"Recognition result = {0}\",  \n          e.Result.Text ?? \"<no text>\");  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"No recognition result\");  \n      }  \n    }  \n  \n    // Handle the EmulateRecognizeCompleted event.   \n    static void EmulateRecognizeCompletedHandler(  \n      object sender, EmulateRecognizeCompletedEventArgs e)  \n    {  \n      if (e.Result == null)  \n      {  \n        Console.WriteLine(\"No result generated.\");  \n      }  \n  \n      completed = true;  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public void EmulateRecognizeAsync (string inputText);
    parameters:
    - id: inputText
      type: System.String
      description: "识别操作输入。"
  overload: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  id: EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: EmulateRecognizeAsync(RecognizedWordUnit[],CompareOptions)
  nameWithType: SpeechRecognizer.EmulateRecognizeAsync(RecognizedWordUnit[],CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(RecognizedWordUnit[],CompareOptions)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "模拟特定单词的共享的语音识别器，用于异步语音识别，而不音频中使用文本的输入，并指定在识别器处理 Unicode 比较单词和加载的语音识别语法的方式。"
  remarks: "此方法创建<xref:System.Speech.Recognition.RecognitionResult>对象使用中提供的信息`wordUnits`参数。</xref:System.Speech.Recognition.RecognitionResult>       识别器使用`compareOptions`当它将语法规则应用于输入的短语。 附带 Vista 和 Windows 7 的识别器忽略大小写，如果<xref:System.Globalization.CompareOptions>或<xref:System.Globalization.CompareOptions>值是否存在。</xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> 识别器始终忽略字符宽度和永远不会忽略假名类型。 识别器还忽略新行和额外的空白区域，并将标点作为文本输入。 有关字符宽度和假名类型的详细信息，请参阅<xref:System.Globalization.CompareOptions>枚举。</xref:System.Globalization.CompareOptions>"
  syntax:
    content: public void EmulateRecognizeAsync (System.Speech.Recognition.RecognizedWordUnit[] wordUnits, System.Globalization.CompareOptions compareOptions);
    parameters:
    - id: wordUnits
      type: System.Speech.Recognition.RecognizedWordUnit[]
      description: "包含有关识别操作的输入 word 单位的数组。"
    - id: compareOptions
      type: System.Globalization.CompareOptions
      description: "描述要用于模拟的识别操作的比较类型的枚举值的按位组合。"
  overload: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)
  id: EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: EmulateRecognizeAsync(String,CompareOptions)
  nameWithType: SpeechRecognizer.EmulateRecognizeAsync(String,CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(String,CompareOptions)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "模拟的短语共享的语音识别器，用于异步语音识别，而不音频中使用文本的输入，并指定如何识别器处理 Unicode 短语和加载的语音识别语法之间的比较。"
  remarks: "识别器使用`compareOptions`当它将语法规则应用于输入的短语。 附带 Vista 和 Windows 7 的识别器忽略大小写，如果<xref:System.Globalization.CompareOptions>或<xref:System.Globalization.CompareOptions>值是否存在。</xref:System.Globalization.CompareOptions> </xref:System.Globalization.CompareOptions> 识别器始终忽略字符宽度和永远不会忽略假名类型。 识别器还忽略新行和额外的空白区域，并将标点作为文本输入。 有关字符宽度和假名类型的详细信息，请参阅<xref:System.Globalization.CompareOptions>枚举。</xref:System.Globalization.CompareOptions>"
  syntax:
    content: public void EmulateRecognizeAsync (string inputText, System.Globalization.CompareOptions compareOptions);
    parameters:
    - id: inputText
      type: System.String
      description: "识别操作输入的短语。"
    - id: compareOptions
      type: System.Globalization.CompareOptions
      description: "描述要用于模拟的识别操作的比较类型的枚举值的按位组合。"
  overload: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted
  id: EmulateRecognizeCompleted
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: EmulateRecognizeCompleted
  nameWithType: SpeechRecognizer.EmulateRecognizeCompleted
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "共享识别器完成模拟输入异步识别操作时发生。"
  remarks: "每个<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>方法开始一个异步识别操作。</xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> 识别器引发`EmulateRecognizeCompleted`事件时它完成异步操作。       异步识别操作可引发<xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected>， <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>， <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>，和<xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized>事件。</xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> </xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected> </xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized> </xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected> EmulateRecognizeCompleted 事件是最后一个这种情况下识别器引发指定的操作。       当你创建的委托`EmulateRecognizeCompleted`事件，需要标识将处理该事件的方法。 若要将事件与事件处理程序关联，添加到事件的委托的一个实例。 除非移除了该委托，称为每当发生该事件时，事件处理程序。 有关事件处理程序委托的详细信息，请参阅[事件和委托](http://go.microsoft.com/fwlink/?LinkId=162418)。"
  example:
  - "The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer. If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition. If Windows Speech Recognition is in the **Sleeping** mode, then <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> always returns null.  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace SharedRecognizer  \n{  \n  class Program  \n  {  \n    // Indicate whether the asynchronous emulate recognition  \n    // operation has completed.  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n    {  \n  \n      // Initialize an instance of the shared recognizer.  \n      using (SpeechRecognizer recognizer = new SpeechRecognizer())  \n      {  \n        // Create and load a sample grammar.  \n        Grammar testGrammar =  \n          new Grammar(new GrammarBuilder(\"testing testing\"));  \n        testGrammar.Name = \"Test Grammar\";  \n        recognizer.LoadGrammar(testGrammar);  \n  \n        // Attach event handlers for recognition events.  \n        recognizer.SpeechRecognized +=   \n          new EventHandler<SpeechRecognizedEventArgs>(SpeechRecognizedHandler);  \n        recognizer.EmulateRecognizeCompleted +=   \n          new EventHandler<EmulateRecognizeCompletedEventArgs>(  \n            EmulateRecognizeCompletedHandler);  \n  \n        completed = false;  \n  \n        // This EmulateRecognizeAsync call generates a SpeechRecognized event.  \n        recognizer.EmulateRecognizeAsync(\"testing testing\");  \n  \n        // Wait for the asynchronous operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n  \n        completed = false;  \n  \n        // This EmulateRecognizeAsync call does not match the grammar  \n        // or generate a SpeechRecognized event.  \n        recognizer.EmulateRecognizeAsync(\"testing one two three\");  \n  \n        // Wait for the asynchronous operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(\"Recognition result = {0}\",  \n          e.Result.Text ?? \"<no text>\");  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"No recognition result\");  \n      }  \n    }  \n  \n    // Handle the EmulateRecognizeCompleted event.  \n    static void EmulateRecognizeCompletedHandler(  \n      object sender, EmulateRecognizeCompletedEventArgs e)  \n    {  \n      if (e.Result == null)  \n      {  \n        Console.WriteLine(\"No result generated.\");  \n      }  \n  \n      // Indicate the asynchronous operation is complete.  \n      completed = true;  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.EmulateRecognizeCompletedEventArgs> EmulateRecognizeCompleted;
    return:
      type: System.EventHandler{System.Speech.Recognition.EmulateRecognizeCompletedEventArgs}
      description: "要添加。"
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.Enabled
  id: Enabled
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: Enabled
  nameWithType: SpeechRecognizer.Enabled
  fullName: System.Speech.Recognition.SpeechRecognizer.Enabled
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "获取或设置一个值，该值指示是否这<xref href=&quot;System.Speech.Recognition.SpeechRecognizer&quot;></xref>对象已准备好处理语音。"
  remarks: "更改此属性不会影响其他实例的<xref:System.Speech.Recognition.SpeechRecognizer>类。</xref:System.Speech.Recognition.SpeechRecognizer>       默认情况下，已启用属性的值是`true` <xref:System.Speech.Recognition.SpeechRecognizer>.</xref:System.Speech.Recognition.SpeechRecognizer>的新实例化实例 识别器处于禁用状态，而的识别器的语音识别语法都可用于识别操作。 设置识别器的 Enabled 属性不起识别器<xref:System.Speech.Recognition.SpeechRecognizer.State%2A>属性。</xref:System.Speech.Recognition.SpeechRecognizer.State%2A>"
  syntax:
    content: public bool Enabled { get; set; }
    return:
      type: System.Boolean
      description: "<xref uid=&quot;langword_csharp_true&quot; name=&quot;true&quot; href=&quot;&quot;></xref>如果此<xref href=&quot;System.Speech.Recognition.SpeechRecognizer&quot;></xref>对象执行语音识别; 否则为<xref uid=&quot;langword_csharp_false&quot; name=&quot;false&quot; href=&quot;&quot;> </xref>。"
  overload: System.Speech.Recognition.SpeechRecognizer.Enabled*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.Grammars
  id: Grammars
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: Grammars
  nameWithType: SpeechRecognizer.Grammars
  fullName: System.Speech.Recognition.SpeechRecognizer.Grammars
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "获取的集合<xref href=&quot;System.Speech.Recognition.Grammar&quot;></xref>中加载的对象<xref href=&quot;System.Speech.Recognition.SpeechRecognizer&quot;></xref>实例。"
  remarks: "此属性不返回任何语音识别语法另一个应用程序加载的。"
  example:
  - "The following example outputs information to the console for each speech recognition grammar loaded into the shared speech recognizer.  \n  \n```c#  \n  \nusing System;  \nusing System.Collections.Generic;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace SharedRecognizer  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n      using (SpeechRecognizer recognizer = new SpeechRecognizer())  \n      {  \n        Grammar sampleGrammar = new Grammar(new GrammarBuilder(\"sample phrase\"));  \n        sampleGrammar.Name = \"Sample Grammar\";  \n        recognizer.LoadGrammar(sampleGrammar);  \n  \n        OutputGrammarList(recognizer);  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    private static void OutputGrammarList(SpeechRecognizer recognizer)  \n    {  \n      List<Grammar> grammars = new List<Grammar>(recognizer.Grammars);  \n      if (grammars.Count > 0)  \n      {  \n        Console.WriteLine(\"Loaded grammars:\");  \n        foreach (Grammar g in grammars)  \n        {  \n          Console.WriteLine(\"  Grammar: {0}\",  \n            (g.Name != null) ? g.Name : \"<no name>\");  \n        }  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"No grammars loaded.\");  \n      }  \n    }  \n}  \n  \n```"
  syntax:
    content: public System.Collections.ObjectModel.ReadOnlyCollection<System.Speech.Recognition.Grammar> Grammars { get; }
    return:
      type: System.Collections.ObjectModel.ReadOnlyCollection{System.Speech.Recognition.Grammar}
      description: "集合<xref href=&quot;System.Speech.Recognition.Grammar&quot;></xref>应用程序加载到共享识别器的当前实例的对象。"
  overload: System.Speech.Recognition.SpeechRecognizer.Grammars*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)
  id: LoadGrammar(System.Speech.Recognition.Grammar)
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: LoadGrammar(Grammar)
  nameWithType: SpeechRecognizer.LoadGrammar(Grammar)
  fullName: System.Speech.Recognition.SpeechRecognizer.LoadGrammar(Grammar)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "加载语音识别语法。"
  remarks: "如果语音识别语法已加载，正在以异步方式加载，或无法加载到任何识别器，则共享识别器引发异常。 如果识别器正在运行，应用程序必须使用<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>暂停之前加载、 卸载、 启用，或禁用语法的语音识别引擎。</xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>       若要以异步方式加载语音识别语法，请使用<xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A>方法。</xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A>"
  example:
  - "The following example is part of a console application that loads a speech recognition grammar and demonstrates asynchronous emulated input, the associated recognition results, and the associated events raised by the speech recognizer. If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition. If Windows Speech Recognition is in the **Sleeping** state, then <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> always returns null.  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \nusing System.Threading;  \n  \nnamespace SharedRecognizer  \n{  \n  class Program  \n  {  \n    // Indicate whether the asynchronous emulate recognition  \n    // operation has completed.  \n    static bool completed;  \n  \n    static void Main(string[] args)  \n    {  \n      // Initialize an instance of the shared recognizer.  \n      using (SpeechRecognizer recognizer = new SpeechRecognizer())  \n      {  \n        // Create and load a sample grammar.  \n        Grammar testGrammar =  \n          new Grammar(new GrammarBuilder(\"testing testing\"));  \n        testGrammar.Name = \"Test Grammar\";  \n  \n        recognizer.LoadGrammar(testGrammar);  \n  \n        // Attach event handlers for recognition events.  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(  \n            SpeechRecognizedHandler);  \n        recognizer.EmulateRecognizeCompleted +=  \n          new EventHandler<EmulateRecognizeCompletedEventArgs>(  \n            EmulateRecognizeCompletedHandler);  \n  \n        completed = false;  \n  \n        // This EmulateRecognizeAsync call generates a SpeechRecognized event.  \n        recognizer.EmulateRecognizeAsync(\"testing testing\");  \n  \n        // Wait for the asynchronous operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n  \n        completed = false;  \n  \n        // This EmulateRecognizeAsync call does not match the grammar   \n        // or generate a SpeechRecognized event.  \n        recognizer.EmulateRecognizeAsync(\"testing one two three\");  \n  \n        // Wait for the asynchronous operation to complete.  \n        while (!completed)  \n        {  \n          Thread.Sleep(333);  \n        }  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void SpeechRecognizedHandler(  \n      object sender, SpeechRecognizedEventArgs e)  \n    {  \n      if (e.Result != null)  \n      {  \n        Console.WriteLine(\"Recognition result = {0}\",  \n          e.Result.Text ?? \"<no text>\");  \n      }  \n      else  \n      {  \n        Console.WriteLine(\"No recognition result\");  \n      }  \n    }   \n  \n    // Handle the EmulateRecognizeCompleted event.   \n    static void EmulateRecognizeCompletedHandler(  \n      object sender, EmulateRecognizeCompletedEventArgs e)  \n    {  \n      if (e.Result == null)  \n      {  \n        Console.WriteLine(\"No result generated.\");  \n      }  \n  \n      completed = true;  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public void LoadGrammar (System.Speech.Recognition.Grammar grammar);
    parameters:
    - id: grammar
      type: System.Speech.Recognition.Grammar
      description: "若要加载语音识别语法。"
  overload: System.Speech.Recognition.SpeechRecognizer.LoadGrammar*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)
  id: LoadGrammarAsync(System.Speech.Recognition.Grammar)
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: LoadGrammarAsync(Grammar)
  nameWithType: SpeechRecognizer.LoadGrammarAsync(Grammar)
  fullName: System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(Grammar)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "异步加载语音识别语法。"
  remarks: "当识别器完成这一异步操作时，将引发<xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted>事件。</xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted> 如果语音识别语法已加载，正在以异步方式加载，或无法加载到任何识别器，则在识别器引发异常。 如果识别器正在运行，应用程序必须使用<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>暂停之前加载、 卸载、 启用，或禁用语法的语音识别引擎。</xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>       若要以同步方式加载语音识别语法，请使用<xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A>方法。</xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A>"
  syntax:
    content: public void LoadGrammarAsync (System.Speech.Recognition.Grammar grammar);
    parameters:
    - id: grammar
      type: System.Speech.Recognition.Grammar
      description: "若要加载语音识别语法。"
  overload: System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted
  id: LoadGrammarCompleted
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: LoadGrammarCompleted
  nameWithType: SpeechRecognizer.LoadGrammarCompleted
  fullName: System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "当识别器完成异步加载的语音识别语法时发生。"
  remarks: "识别器<xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A>方法启动异步操作。</xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A> 识别器引发`LoadGrammarCompleted`事件完成该操作。 若要获取<xref:System.Speech.Recognition.Grammar>识别器加载的对象使用<xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs.Grammar%2A>的关联<xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs>。</xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs>属性</xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs.Grammar%2A></xref:System.Speech.Recognition.Grammar> 若要获取当前<xref:System.Speech.Recognition.Grammar>对象识别器已加载，使用识别器<xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A>属性。</xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A> </xref:System.Speech.Recognition.Grammar>       当你创建的委托`LoadGrammarCompleted`事件，需要标识将处理该事件的方法。 若要将事件与事件处理程序关联，添加到事件的委托的一个实例。 除非移除了该委托，称为每当发生该事件时，事件处理程序。 有关事件处理程序委托的详细信息，请参阅[事件和委托](http://go.microsoft.com/fwlink/?LinkId=162418)。"
  example:
  - "The following example creates a shared speech recognizer, and then creates two types of grammars for recognizing specific words and for accepting free dictation. The example asynchronously loads all the created grammars to the recognizer. Handlers for the recognizer's LoadGrammarCompleted and <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized> events write to the console the name of the grammar that was used to perform the recognition and the text of the recognition result, respectively.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    private static SpeechRecognizer recognizer;  \n    public static void Main(string[] args)  \n    {  \n  \n      // Initialize a shared speech recognition engine.  \n      recognizer = new SpeechRecognizer();  \n  \n        // Add a handler for the LoadGrammarCompleted event.  \n        recognizer.LoadGrammarCompleted +=  \n          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n  \n        // Add a handler for the SpeechRecognized event.  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n  \n        // Add a handler for the StateChanged event.  \n        recognizer.StateChanged +=  \n          new EventHandler<StateChangedEventArgs>(recognizer_StateChanged);  \n  \n        // Create \"yesno\" grammar.  \n        Choices yesChoices = new Choices(new string[] { \"yes\", \"yup\", \"yeah}\" });  \n        SemanticResultValue yesValue =  \n            new SemanticResultValue(yesChoices, (bool)true);  \n        Choices noChoices = new Choices(new string[] { \"no\", \"nope\", \"neah\" });  \n        SemanticResultValue noValue =  \n            new SemanticResultValue(noChoices, (bool)false);  \n        SemanticResultKey yesNoKey =  \n            new SemanticResultKey(\"yesno\", new Choices(new GrammarBuilder[] { yesValue, noValue }));  \n        Grammar yesnoGrammar = new Grammar(yesNoKey);  \n        yesnoGrammar.Name = \"yesNo\";  \n  \n        // Create \"done\" grammar.  \n        Grammar doneGrammar =  \n          new Grammar(new Choices(new string[] { \"done\", \"exit\", \"quit\", \"stop\" }));  \n        doneGrammar.Name = \"Done\";  \n  \n        // Create dictation grammar.  \n        Grammar dictation = new DictationGrammar();  \n        dictation.Name = \"Dictation\";  \n  \n        // Load grammars to the recognizer.  \n        recognizer.LoadGrammarAsync(yesnoGrammar);  \n        recognizer.LoadGrammarAsync(doneGrammar);  \n        recognizer.LoadGrammarAsync(dictation);  \n  \n        // Keep the console window open.  \n        Console.ReadLine();  \n      }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Grammar({0}): {1}\", e.Result.Grammar.Name, e.Result.Text);  \n  \n      // Add event handler code here.  \n    }  \n  \n    // Handle the LoadGrammarCompleted event.   \n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n      string grammarName = e.Grammar.Name;  \n      bool grammarLoaded = e.Grammar.Loaded;  \n  \n      if (e.Error != null)  \n      {  \n        Console.WriteLine(\"LoadGrammar for {0} failed with a {1}.\",  \n        grammarName, e.Error.GetType().Name);  \n  \n        // Add exception handling code here.  \n      }  \n  \n      Console.WriteLine(\"Grammar {0} {1} loaded.\",  \n      grammarName, (grammarLoaded) ? \"is\" : \"is not\");  \n    }  \n  \n    // Put the shared speech recognizer into \"listening\" mode.   \n    static void recognizer_StateChanged(object sender, StateChangedEventArgs e)  \n    {  \n      if (e.RecognizerState != RecognizerState.Stopped)  \n      {  \n        recognizer.EmulateRecognizeAsync(\"Start listening\");  \n      }  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.LoadGrammarCompletedEventArgs> LoadGrammarCompleted;
    return:
      type: System.EventHandler{System.Speech.Recognition.LoadGrammarCompletedEventArgs}
      description: "要添加。"
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.MaxAlternates
  id: MaxAlternates
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: MaxAlternates
  nameWithType: SpeechRecognizer.MaxAlternates
  fullName: System.Speech.Recognition.SpeechRecognizer.MaxAlternates
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "获取或设置的最大共享识别器返回的每个识别操作的备用识别结果数。"
  remarks: "<xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>属性<xref:System.Speech.Recognition.RecognitionResult>类包含的集合<xref:System.Speech.Recognition.RecognizedPhrase>表示输入其他候选解释的对象。</xref:System.Speech.Recognition.RecognizedPhrase> </xref:System.Speech.Recognition.RecognitionResult> </xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>       MaxAlternates 的默认值为 10。"
  syntax:
    content: public int MaxAlternates { get; set; }
    return:
      type: System.Int32
      description: "最大备用语音识别器针对每个识别操作返回的结果数。"
  overload: System.Speech.Recognition.SpeechRecognizer.MaxAlternates*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition
  id: PauseRecognizerOnRecognition
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: PauseRecognizerOnRecognition
  nameWithType: SpeechRecognizer.PauseRecognizerOnRecognition
  fullName: System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "获取或设置一个值，该值指示是否共享识别器暂停识别操作处理应用程序时<xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&quot;></xref>事件。"
  remarks: "将此属性设置为`true`，如果在<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>你的应用程序需要更改语音识别服务的状态或语音识别服务处理更多输入之前更改加载或启用语音识别语法的事件处理程序。</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>      1> [!NOTE]&1;> 设置<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>属性`true`导致每个<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>中每个应用程序阻止 Windows 语音识别服务事件处理程序。</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> </xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>       若要与应用程序状态同步对共享识别器的更改，使用<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>方法。</xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>       PauseRecognizerOnRecognition 时`true`，执行期间<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>处理程序语音识别服务暂停，在其到达时缓冲新音频输入。</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized> 一次<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>事件处理程序退出，语音识别服务继续识别和处理从其输入缓冲区的信息的启动。</xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>       若要启用或禁用语音识别服务，请使用<xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A>属性。</xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A>"
  syntax:
    content: public bool PauseRecognizerOnRecognition { get; set; }
    return:
      type: System.Boolean
      description: "<xref uid=&quot;langword_csharp_true&quot; name=&quot;true&quot; href=&quot;&quot;></xref>如果共享识别器等待处理输入，而处理任何应用程序<xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&quot;></xref>事件; 否则为<xref uid=&quot;langword_csharp_false&quot; name=&quot;false&quot; href=&quot;&quot;> </xref>。"
  overload: System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition
  id: RecognizerAudioPosition
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: RecognizerAudioPosition
  nameWithType: SpeechRecognizer.RecognizerAudioPosition
  fullName: System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "获取识别器音频输入，它正在处理中的当前位置。"
  remarks: "`RecognizerAudioPosition`属性引用中处理其音频输入识别器的位置。 与此相反，<xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>属性引用在其生成的音频流中的输入的设备的位置。</xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A> 这些位置可以是不同的。 例如，如果收到识别器输入其具有不但 RecognizerAudioPosition 属性的值是小于的值生成识别结果<xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>属性。</xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>"
  syntax:
    content: public TimeSpan RecognizerAudioPosition { get; }
    return:
      type: System.TimeSpan
      description: "音频输入，它正在处理中识别器位置。"
  overload: System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.RecognizerInfo
  id: RecognizerInfo
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: RecognizerInfo
  nameWithType: SpeechRecognizer.RecognizerInfo
  fullName: System.Speech.Recognition.SpeechRecognizer.RecognizerInfo
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "获取共享的语音识别器有关的信息。"
  remarks: "此属性返回由 Windows 语音识别中使用语音识别器有关的信息。"
  example:
  - "The following example sends information about the shared recognizer to the console.  \n  \n```c#  \n  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SharedRecognizer  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n    {  \n      using (SpeechRecognizer recognizer = new SpeechRecognizer())  \n      {  \n        Console.WriteLine(\"Recognizer information for the shared recognizer:\");  \n        Console.WriteLine(\"  Name: {0}\", recognizer.RecognizerInfo.Name);  \n        Console.WriteLine(\"  Culture: {0}\", recognizer.RecognizerInfo.Culture.ToString());  \n        Console.WriteLine(\"  Description: {0}\", recognizer.RecognizerInfo.Description);  \n      }  \n  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public System.Speech.Recognition.RecognizerInfo RecognizerInfo { get; }
    return:
      type: System.Speech.Recognition.RecognizerInfo
      description: "共享的语音识别器有关的信息。"
  overload: System.Speech.Recognition.SpeechRecognizer.RecognizerInfo*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached
  id: RecognizerUpdateReached
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: RecognizerUpdateReached
  nameWithType: SpeechRecognizer.RecognizerUpdateReached
  fullName: System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "识别器暂停同步识别和其他操作时发生。"
  remarks: "应用程序必须使用<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>暂停正在运行的实例<xref:System.Speech.Recognition.SpeechRecognizer>之前修改其<xref:System.Speech.Recognition.Grammar>对象。</xref:System.Speech.Recognition.Grammar> </xref:System.Speech.Recognition.SpeechRecognizer> </xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> 例如，虽然<xref:System.Speech.Recognition.SpeechRecognizer>是暂停，你可以加载、 卸载、 启用和禁用<xref:System.Speech.Recognition.Grammar>对象。</xref:System.Speech.Recognition.Grammar> </xref:System.Speech.Recognition.SpeechRecognizer> <xref:System.Speech.Recognition.SpeechRecognizer>已准备好接受修改时引发此事件。</xref:System.Speech.Recognition.SpeechRecognizer>       当创建 RecognizerUpdateReached 事件的委托时，需要标识将处理该事件的方法。 若要将事件与事件处理程序关联，添加到事件的委托的一个实例。 除非移除了该委托，称为每当发生该事件时，事件处理程序。 有关事件处理程序委托的详细信息，请参阅[事件和委托](http://go.microsoft.com/fwlink/?LinkId=162418)。"
  example:
  - "The following example shows a console application that loads and unloads <xref:System.Speech.Recognition.Grammar> objects. The application uses the <xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> method to request the speech recognition engine to pause so it can receive an update. The application then loads or unloads a <xref:System.Speech.Recognition.Grammar> object.  \n  \n At each update, a handler for RecognizerUpdateReached event writes the name and status of the currently loaded <xref:System.Speech.Recognition.Grammar> objects to the console. As grammars are loaded and unloaded, the application first recognizes the names of farm animals, then the names of farm animals and the names of fruits, then only the names of fruits.  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \nusing System.Collections.Generic;  \nusing System.Threading;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    private static SpeechRecognizer recognizer;  \n    public static void Main(string[] args)  \n    {  \n  \n      // Initialize a shared speech recognition engine.  \n      recognizer = new SpeechRecognizer();  \n  \n      // Create the first grammar - Farm.  \n      Choices animals = new Choices(new string[] { \"cow\", \"pig\", \"goat\" });  \n      GrammarBuilder farm = new GrammarBuilder(animals);  \n      Grammar farmAnimals = new Grammar(farm);  \n      farmAnimals.Name = \"Farm\";  \n  \n      // Create the second grammar - Fruit.  \n      Choices fruit = new Choices(new string[] { \"apples\", \"peaches\", \"oranges\" });  \n      GrammarBuilder favorite = new GrammarBuilder(fruit);  \n      Grammar favoriteFruit = new Grammar(favorite);  \n      favoriteFruit.Name = \"Fruit\";  \n  \n      // Attach event handlers.  \n      recognizer.SpeechRecognized +=  \n        new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n      recognizer.RecognizerUpdateReached +=  \n        new EventHandler<RecognizerUpdateReachedEventArgs>(recognizer_RecognizerUpdateReached);  \n      recognizer.StateChanged +=   \n        new EventHandler<StateChangedEventArgs>(recognizer_StateChanged);  \n  \n      // Load the Farm grammar.  \n      recognizer.LoadGrammar(farmAnimals);  \n      Console.WriteLine(\"Grammar Farm is loaded\");  \n  \n      // Pause to recognize farm animals.  \n      Thread.Sleep(7000);  \n      Console.WriteLine();  \n  \n      // Request an update and load the Fruit grammar.  \n      recognizer.RequestRecognizerUpdate();  \n      recognizer.LoadGrammarAsync(favoriteFruit);  \n      Thread.Sleep(5000);  \n  \n      // Request an update and unload the Farm grammar.  \n      recognizer.RequestRecognizerUpdate();  \n      recognizer.UnloadGrammar(farmAnimals);  \n      Thread.Sleep(5000);  \n  \n      // Keep the console window open.  \n      Console.WriteLine();  \n      Console.WriteLine(\"Press any key to exit...\");  \n      Console.ReadKey();  \n    }  \n  \n    // Put the shared speech recognizer into \"listening\" mode.  \n    static void recognizer_StateChanged(object sender, StateChangedEventArgs e)  \n    {  \n      if (e.RecognizerState != RecognizerState.Stopped)  \n      {  \n        recognizer.EmulateRecognizeAsync(\"Start listening\");  \n      }  \n    }  \n  \n    // At the update, get the names and enabled status of the currently loaded grammars.  \n    public static void recognizer_RecognizerUpdateReached(  \n      object sender, RecognizerUpdateReachedEventArgs e)  \n    {  \n      Console.WriteLine();  \n      Console.WriteLine(\"Update reached:\");  \n      Thread.Sleep(1000);  \n  \n      string qualifier;  \n      List<Grammar> grammars = new List<Grammar>(recognizer.Grammars);  \n      foreach (Grammar g in grammars)  \n      {  \n        qualifier = (g.Enabled) ? \"enabled\" : \"disabled\";  \n        Console.WriteLine(\"  Grammar {0} is loaded and is {1}.\",  \n        g.Name, qualifier);  \n      }  \n    }  \n  \n    // Write the text of the recognized phrase to the console.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"  Speech recognized: \" + e.Result.Text);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.RecognizerUpdateReachedEventArgs> RecognizerUpdateReached;
    return:
      type: System.EventHandler{System.Speech.Recognition.RecognizerUpdateReachedEventArgs}
      description: "要添加。"
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate
  id: RequestRecognizerUpdate
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: RequestRecognizerUpdate()
  nameWithType: SpeechRecognizer.RequestRecognizerUpdate()
  fullName: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate()
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "共享识别器暂停并更新其状态的请求。"
  remarks: "当识别器生成<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>事件，<xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A>属性<xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs>是`null`。</xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs> </xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A> </xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>       若要提供用户标记，使用<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>或<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>方法。</xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> </xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> 若要指定的音频位置偏移量，请使用<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>方法。</xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>"
  syntax:
    content: public void RequestRecognizerUpdate ();
    parameters: []
  overload: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object)
  id: RequestRecognizerUpdate(System.Object)
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: RequestRecognizerUpdate(Object)
  nameWithType: SpeechRecognizer.RequestRecognizerUpdate(Object)
  fullName: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(Object)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "共享识别器暂停和更新其状态以及关联的事件提供的用户令牌的请求。"
  remarks: "当识别器生成<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>事件，<xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A>属性<xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs>包含值的`userToken`参数。</xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs> </xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A> </xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>       若要指定的音频位置偏移量，请使用<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>方法。</xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>"
  syntax:
    content: public void RequestRecognizerUpdate (object userToken);
    parameters:
    - id: userToken
      type: System.Object
      description: "包含有关操作的信息的用户定义的信息。"
  overload: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object,System.TimeSpan)
  id: RequestRecognizerUpdate(System.Object,System.TimeSpan)
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: RequestRecognizerUpdate(Object,TimeSpan)
  nameWithType: SpeechRecognizer.RequestRecognizerUpdate(Object,TimeSpan)
  fullName: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(Object,TimeSpan)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "共享识别器暂停和更新其状态以及关联的事件提供偏移量和用户令牌的请求。"
  remarks: "识别器并不会启动之前识别器识别器更新请求<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>等于当前<xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>加的值上`audioPositionAheadToRaiseUpdate`参数。</xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A> </xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>       当识别器生成<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>事件，<xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A>属性<xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs>包含值的`userToken`参数。</xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs> </xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A> </xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached>"
  syntax:
    content: public void RequestRecognizerUpdate (object userToken, TimeSpan audioPositionAheadToRaiseUpdate);
    parameters:
    - id: userToken
      type: System.Object
      description: "包含有关操作的信息的用户定义的信息。"
    - id: audioPositionAheadToRaiseUpdate
      type: System.TimeSpan
      description: "从当前的偏移量<xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition*>延迟请求。</xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition*>"
  overload: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.SpeechDetected
  id: SpeechDetected
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: SpeechDetected
  nameWithType: SpeechRecognizer.SpeechDetected
  fullName: System.Speech.Recognition.SpeechRecognizer.SpeechDetected
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "当识别器检测到它可将其识别为语音的输入时发生。"
  remarks: "共享识别器可以引发此事件以响应输入。 <xref:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition%2A>属性关联的<xref:System.Speech.Recognition.SpeechDetectedEventArgs>对象指示在其中识别器检测到语音的输入流中的位置。</xref:System.Speech.Recognition.SpeechDetectedEventArgs> </xref:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition%2A> 有关详细信息请参阅<xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>和<xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A>属性和<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A>和<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>方法。</xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> </xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A> </xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A> </xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A>       当创建 SpeechDetected 事件的委托时，需要标识将处理该事件的方法。 若要将事件与事件处理程序关联，添加到事件的委托的一个实例。 除非移除了该委托，称为每当发生该事件时，事件处理程序。 有关事件处理程序委托的详细信息，请参阅[事件和委托](http://go.microsoft.com/fwlink/?LinkId=162418)。"
  example:
  - "The following example is part of a console application for choosing origin and destination cities for a flight. The application recognizes phrases such as \"I want to fly from Miami to Chicago.\"  The example uses the SpeechDetected event to report the <xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A> each time speech is detected.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n  \n    // Initialize a shared speech recognition engine.  \n    {  \n      using (SpeechRecognizer recognizer =  \n         new SpeechRecognizer())  \n      {  \n  \n        // Create a grammar.  \n        Choices cities = new Choices(new string[] {   \n          \"Los Angeles\", \"New York\", \"Chicago\", \"San Francisco\", \"Miami\", \"Dallas\" });  \n  \n        GrammarBuilder gb = new GrammarBuilder();  \n        gb.Append(\"I would like to fly from\");  \n        gb.Append(cities);  \n        gb.Append(\"to\");  \n        gb.Append(cities);  \n  \n        // Create a Grammar object and load it to the recognizer.  \n        Grammar g = new Grammar(gb);  \n        g.Name = (\"City Chooser\");  \n        recognizer.LoadGrammarAsync(g);  \n  \n        // Attach event handlers.  \n        recognizer.LoadGrammarCompleted +=  \n          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n        recognizer.SpeechDetected +=   \n          new EventHandler<SpeechDetectedEventArgs>(recognizer_SpeechDetected);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n  \n        // Keep the console window open.  \n        Console.ReadLine();  \n      }  \n    }  \n  \n    // Handle the SpeechDetected event.  \n    static void recognizer_SpeechDetected(object sender, SpeechDetectedEventArgs e)  \n    {  \n      Console.WriteLine(\"Speech detected at AudioPosition = {0}\", e.AudioPosition);  \n    }  \n  \n    // Handle the LoadGrammarCompleted event.  \n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"Grammar loaded: \" + e.Grammar.Name);  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Speech recognized: \" + e.Result.Text);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.SpeechDetectedEventArgs> SpeechDetected;
    return:
      type: System.EventHandler{System.Speech.Recognition.SpeechDetectedEventArgs}
      description: "要添加。"
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized
  id: SpeechHypothesized
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: SpeechHypothesized
  nameWithType: SpeechRecognizer.SpeechHypothesized
  fullName: System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "当识别器已识别的词或可能是语法中的多个完成短语的一个组件的单词时出现。"
  remarks: "共享识别器可以引发此事件时的输入是不明确。 例如，对于支持识别的语音识别语法&quot;新游戏请&quot;或&quot;新游戏&quot;，&quot;新游戏请&quot;是明确的输入，和&quot;新游戏&quot;是不明确的输入。       当创建 SpeechHypothesized 事件的委托时，需要标识将处理该事件的方法。 若要将事件与事件处理程序关联，添加到事件的委托的一个实例。 除非移除了该委托，称为每当发生该事件时，事件处理程序。 有关事件处理程序委托的详细信息，请参阅[事件和委托](http://go.microsoft.com/fwlink/?LinkId=162418)。"
  example:
  - "The following example recognizes phrases such as \"Display the list of artists in the jazz category\". The example uses the SpeechHypothesized event to display incomplete phrase fragments in the console as they are recognized.  \n  \n```  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n  \n    // Initialize a shared speech recognition engine.  \n    {  \n      using (SpeechRecognizer recognizer =  \n         new SpeechRecognizer())  \n      {  \n  \n        // Create a grammar.  \n        //  Create lists of alternative choices.  \n        Choices listTypes = new Choices(new string[] { \"albums\", \"artists\" });  \n        Choices genres = new Choices(new string[] {   \n          \"blues\", \"classical\", \"gospel\", \"jazz\", \"rock\" });  \n  \n        //  Create a GrammarBuilder object and assemble the grammar components.  \n        GrammarBuilder mediaMenu = new GrammarBuilder(\"Display the list of\");  \n        mediaMenu.Append(listTypes);  \n        mediaMenu.Append(\"in the\");  \n        mediaMenu.Append(genres);  \n        mediaMenu.Append(\"category.\");  \n  \n        //  Build a Grammar object from the GrammarBuilder.  \n        Grammar mediaMenuGrammar = new Grammar(mediaMenu);  \n        mediaMenuGrammar.Name = \"Media Chooser\";  \n  \n        // Attach event handlers.  \n        recognizer.LoadGrammarCompleted +=  \n          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n        recognizer.SpeechHypothesized +=   \n          new EventHandler<SpeechHypothesizedEventArgs>(recognizer_SpeechHypothesized);  \n  \n        // Load the grammar object to the recognizer.  \n        recognizer.LoadGrammarAsync(mediaMenuGrammar);  \n  \n        // Keep the console window open.  \n        Console.ReadLine();  \n      }  \n    }  \n  \n    // Handle the SpeechHypothesized event.  \n    static void recognizer_SpeechHypothesized(object sender, SpeechHypothesizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Speech hypothesized: \" + e.Result.Text);  \n    }  \n  \n    // Handle the LoadGrammarCompleted event.  \n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"Grammar loaded: \" + e.Grammar.Name);  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Speech recognized: \" + e.Result.Text);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.SpeechHypothesizedEventArgs> SpeechHypothesized;
    return:
      type: System.EventHandler{System.Speech.Recognition.SpeechHypothesizedEventArgs}
      description: "要添加。"
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected
  id: SpeechRecognitionRejected
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: SpeechRecognitionRejected
  nameWithType: SpeechRecognizer.SpeechRecognitionRejected
  fullName: System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "当识别器接收语音识别语法已加载的任何不匹配的输入时发生。"
  remarks: "如果确定，输入不足够的置信度的任何不匹配加载的语音识别语法，共享识别器将引发此事件。 <xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A>属性<xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs>包含拒绝<xref:System.Speech.Recognition.RecognitionResult>对象。</xref:System.Speech.Recognition.RecognitionResult> </xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs> </xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A>       在共享识别，也就是由管理器的置信度阈值<xref:System.Speech.Recognition.SpeechRecognizer>、 具有用户配置文件相关联并存储在 Windows 注册表。</xref:System.Speech.Recognition.SpeechRecognizer> 应用程序不应写入属性的共享识别器注册表的更改。       当创建 SpeechRecognitionRejected 事件的委托时，需要标识将处理该事件的方法。 若要将事件与事件处理程序关联，添加到事件的委托的一个实例。 除非移除了该委托，称为每当发生该事件时，事件处理程序。 有关事件处理程序委托的详细信息，请参阅[事件和委托](http://go.microsoft.com/fwlink/?LinkId=162418)。"
  example:
  - "The following example recognizes phrases such as \"Display the list of artists in the jazz category\" or \"Display albums gospel\". The example uses a handler for the SpeechRecognitionRejected event to display a notification in the console when the speech input cannot be matched to the contents of the grammar with sufficient confidence to produce a successful recognition.  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n  \n    // Initialize a shared speech recognition engine.  \n    {  \n      using (SpeechRecognizer recognizer =  \n         new SpeechRecognizer())  \n      {  \n  \n        // Create a grammar.  \n        //  Create lists of alternative choices.  \n        Choices listTypes = new Choices(new string[] { \"albums\", \"artists\" });  \n        Choices genres = new Choices(new string[] {   \n          \"blues\", \"classical\", \"gospel\", \"jazz\", \"rock\" });  \n  \n        //  Create a GrammarBuilder object and assemble the grammar components.  \n        GrammarBuilder mediaMenu = new GrammarBuilder(\"Display\");  \n        mediaMenu.Append(\"the list of\", 0, 1);  \n        mediaMenu.Append(listTypes);  \n        mediaMenu.Append(\"in the\", 0, 1);  \n        mediaMenu.Append(genres);  \n        mediaMenu.Append(\"category\", 0, 1);  \n  \n        //  Build a Grammar object from the GrammarBuilder.  \n        Grammar mediaMenuGrammar = new Grammar(mediaMenu);  \n        mediaMenuGrammar.Name = \"Media Chooser\";  \n  \n        // Attach event handlers.  \n        recognizer.LoadGrammarCompleted +=  \n          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n        recognizer.SpeechRecognized +=  \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n        recognizer.SpeechRecognitionRejected +=   \n          new EventHandler<SpeechRecognitionRejectedEventArgs>(recognizer_SpeechRecognitionRejected);  \n  \n        // Load the grammar object to the recognizer.  \n        recognizer.LoadGrammarAsync(mediaMenuGrammar);  \n  \n        // Keep the console window open.  \n        Console.ReadLine();  \n      }  \n    }  \n  \n    // Handle the SpeechRecognitionRejected event.  \n    static void recognizer_SpeechRecognitionRejected(object sender, SpeechRecognitionRejectedEventArgs e)  \n    {  \n      Console.WriteLine(\"Speech input was rejected.\");  \n    }  \n  \n    // Handle the LoadGrammarCompleted event.  \n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"Grammar loaded: \" + e.Grammar.Name);  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Speech recognized: \" + e.Result.Text);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.SpeechRecognitionRejectedEventArgs> SpeechRecognitionRejected;
    return:
      type: System.EventHandler{System.Speech.Recognition.SpeechRecognitionRejectedEventArgs}
      description: "要添加。"
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.SpeechRecognized
  id: SpeechRecognized
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: SpeechRecognized
  nameWithType: SpeechRecognizer.SpeechRecognized
  fullName: System.Speech.Recognition.SpeechRecognizer.SpeechRecognized
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "当识别器接收其语音识别语法之一匹配的输入时发生。"
  remarks: "识别器引发`SpeechRecognized`事件如果输入与匹配加载并已启用语音识别语法之一的足够自信地确定。 <xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A>属性<xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs>包含接受<xref:System.Speech.Recognition.RecognitionResult>对象。</xref:System.Speech.Recognition.RecognitionResult> </xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs> </xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A>       在共享识别，也就是由管理器的置信度阈值<xref:System.Speech.Recognition.SpeechRecognizer>、 具有用户配置文件相关联并存储在 Windows 注册表。</xref:System.Speech.Recognition.SpeechRecognizer> 应用程序不应写入属性的共享识别器注册表的更改。       当识别器收到与匹配语法中，输入的<xref:System.Speech.Recognition.Grammar>对象可以引发<xref:System.Speech.Recognition.Grammar.SpeechRecognized>事件。</xref:System.Speech.Recognition.Grammar.SpeechRecognized> </xref:System.Speech.Recognition.Grammar> <xref:System.Speech.Recognition.Grammar>对象的<xref:System.Speech.Recognition.Grammar.SpeechRecognized>在语音识别器 SpeechRecognized 事件之前引发事件。</xref:System.Speech.Recognition.Grammar.SpeechRecognized> </xref:System.Speech.Recognition.Grammar>       当创建 SpeechRecognized 事件的委托时，需要标识将处理该事件的方法。 若要将事件与事件处理程序关联，添加到事件的委托的一个实例。 除非移除了该委托，称为每当发生该事件时，事件处理程序。 有关事件处理程序委托的详细信息，请参阅[事件和委托](http://go.microsoft.com/fwlink/?LinkId=162418)。"
  example:
  - "The following example is part of a console application that loads a speech recognition grammar and demonstrates speech input to the shared recognizer, the associated recognition results, and the associated events raised by the speech recognizer. If Windows Speech Recognition is not running, then starting this application will also start Windows Speech Recognition.  \n  \n Spoken input such as \"I want to fly from Chicago to Miami\" will trigger a SpeechRecognized event. Speaking the phrase \"Fly me from Houston to Chicago \" will not trigger a SpeechRecognized event.  \n  \n The example uses a handler for the SpeechRecognized event to display successfully recognized phrases and the semantics they contain in the console.  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    static void Main(string[] args)  \n  \n    // Initialize a shared speech recognition engine.  \n    {  \n      using (SpeechRecognizer recognizer = new SpeechRecognizer())  \n      {  \n  \n        // Create SemanticResultValue objects that contain cities and airport codes.  \n        SemanticResultValue chicago = new SemanticResultValue(\"Chicago\", \"ORD\");  \n        SemanticResultValue boston = new SemanticResultValue(\"Boston\", \"BOS\");  \n        SemanticResultValue miami = new SemanticResultValue(\"Miami\", \"MIA\");  \n        SemanticResultValue dallas = new SemanticResultValue(\"Dallas\", \"DFW\");  \n  \n        // Create a Choices object and add the SemanticResultValue objects, using  \n        // implicit conversion from SemanticResultValue to GrammarBuilder  \n        Choices cities = new Choices();  \n        cities.Add(new Choices(new GrammarBuilder[] { chicago, boston, miami, dallas }));  \n  \n        // Build the phrase and add SemanticResultKeys.  \n        GrammarBuilder chooseCities = new GrammarBuilder();  \n        chooseCities.Append(\"I want to fly from\");  \n        chooseCities.Append(new SemanticResultKey(\"origin\", cities));  \n        chooseCities.Append(\"to\");  \n        chooseCities.Append(new SemanticResultKey(\"destination\", cities));  \n  \n        // Build a Grammar object from the GrammarBuilder.  \n        Grammar bookFlight = new Grammar(chooseCities);  \n        bookFlight.Name = \"Book Flight\";  \n  \n        // Add a handler for the LoadGrammarCompleted event.  \n        recognizer.LoadGrammarCompleted +=  \n          new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n  \n        // Add a handler for the SpeechRecognized event.  \n        recognizer.SpeechRecognized +=   \n          new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n  \n        // Load the grammar object to the recognizer.  \n        recognizer.LoadGrammarAsync(bookFlight);  \n  \n        // Keep the console window open.  \n        Console.ReadLine();  \n      }  \n    }  \n  \n    // Handle the LoadGrammarCompleted event.  \n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n      Console.WriteLine(\"Grammar loaded: \" + e.Grammar.Name);  \n      Console.WriteLine();  \n    }  \n  \n    // Handle the SpeechRecognized event.  \n    static void recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n      Console.WriteLine(\"Speech recognized:  \" + e.Result.Text);  \n      Console.WriteLine();  \n      Console.WriteLine(\"Semantic results:\");  \n      Console.WriteLine(\"  The flight origin is \" + e.Result.Semantics[\"origin\"].Value);  \n      Console.WriteLine(\"  The flight destination is \" + e.Result.Semantics[\"destination\"].Value);  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.SpeechRecognizedEventArgs> SpeechRecognized;
    return:
      type: System.EventHandler{System.Speech.Recognition.SpeechRecognizedEventArgs}
      description: "要添加。"
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.State
  id: State
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: State
  nameWithType: SpeechRecognizer.State
  fullName: System.Speech.Recognition.SpeechRecognizer.State
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "获取的状态<xref href=&quot;System.Speech.Recognition.SpeechRecognizer&quot;></xref>对象。"
  remarks: "此只读属性指示是否为驻留在 Windows 中共享的识别`Stopped`或`Listening`状态。 有关详细信息，请参阅<xref:System.Speech.Recognition.RecognizerState>枚举。</xref:System.Speech.Recognition.RecognizerState>"
  syntax:
    content: public System.Speech.Recognition.RecognizerState State { get; }
    return:
      type: System.Speech.Recognition.RecognizerState
      description: "状态<xref uid=&quot;langword_csharp_SpeechRecognizer&quot; name=&quot;SpeechRecognizer&quot; href=&quot;&quot;></xref>对象。"
  overload: System.Speech.Recognition.SpeechRecognizer.State*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.StateChanged
  id: StateChanged
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: StateChanged
  nameWithType: SpeechRecognizer.StateChanged
  fullName: System.Speech.Recognition.SpeechRecognizer.StateChanged
  type: Event
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Windows 桌面语音技术识别引擎的运行状态更改时发生。"
  remarks: "共享识别器引发此事件时 Windows 语音识别的状态更改为<xref:System.Speech.Recognition.RecognizerState>或<xref:System.Speech.Recognition.RecognizerState>状态。</xref:System.Speech.Recognition.RecognizerState> </xref:System.Speech.Recognition.RecognizerState>       若要在事件的时间获取共享识别器的状态，使用<xref:System.Speech.Recognition.StateChangedEventArgs.RecognizerState%2A>的关联<xref:System.Speech.Recognition.StateChangedEventArgs>。</xref:System.Speech.Recognition.StateChangedEventArgs>属性</xref:System.Speech.Recognition.StateChangedEventArgs.RecognizerState%2A> 若要获取共享识别器的当前状态，请使用识别器<xref:System.Speech.Recognition.SpeechRecognizer.State%2A>属性。</xref:System.Speech.Recognition.SpeechRecognizer.State%2A>       当创建 StateChanged 事件的委托时，需要标识将处理该事件的方法。 若要将事件与事件处理程序关联，添加到事件的委托的一个实例。 除非移除了该委托，称为每当发生该事件时，事件处理程序。 有关事件处理程序委托的详细信息，请参阅[事件和委托](http://go.microsoft.com/fwlink/?LinkId=162418)。"
  example:
  - "The following example creates a shared speech recognizer, and then creates two types of grammars for recognizing specific words and for accepting free dictation. The example asynchronously loads all the created grammars to the recognizer.  A handler for the StateChanged event uses the <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A> method to put Windows Recognition in \"listening\" mode.  \n  \n```c#  \nusing System;  \nusing System.Speech.Recognition;  \n  \nnamespace SampleRecognition  \n{  \n  class Program  \n  {  \n    private static SpeechRecognizer recognizer;  \n    public static void Main(string[] args)  \n    {  \n  \n      // Initialize a shared speech recognition engine.  \n      recognizer = new SpeechRecognizer();  \n  \n      // Add a handler for the LoadGrammarCompleted event.  \n      recognizer.LoadGrammarCompleted += new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \n  \n      // Add a handler for the SpeechRecognized event.  \n      recognizer.SpeechRecognized += new EventHandler<SpeechRecognizedEventArgs>(recognizer_SpeechRecognized);  \n  \n      // Add a handler for the StateChanged event.  \n      recognizer.StateChanged += new EventHandler<StateChangedEventArgs>(recognizer_StateChanged);  \n  \n      // Create \"yesno\" grammar.  \n      Choices yesChoices = new Choices(new string[] { \"yes\", \"yup\", \"yah}\" });  \n      SemanticResultValue yesValue =  \n          new SemanticResultValue(yesChoices, (bool)true);  \n      Choices noChoices = new Choices(new string[] { \"no\", \"nope\", \"nah\" });  \n      SemanticResultValue noValue = new SemanticResultValue(noChoices, (bool)false);  \n      SemanticResultKey yesNoKey =  \n          new SemanticResultKey(\"yesno\", new Choices(new GrammarBuilder[] { yesValue, noValue }));  \n      Grammar yesnoGrammar = new Grammar(yesNoKey);  \n      yesnoGrammar.Name = \"yesNo\";  \n  \n      // Create \"done\" grammar.  \n      Grammar doneGrammar =  \n        new Grammar(new Choices(new string[] { \"done\", \"exit\", \"quit\", \"stop\" }));  \n      doneGrammar.Name = \"Done\";  \n  \n      // Create dictation grammar.  \n      Grammar dictation = new DictationGrammar();  \n      dictation.Name = \"Dictation\";  \n  \n      // Load grammars to the recognizer.  \n      recognizer.LoadGrammarAsync(yesnoGrammar);  \n      recognizer.LoadGrammarAsync(doneGrammar);  \n      recognizer.LoadGrammarAsync(dictation);  \n  \n      // Keep the console window open.  \n      Console.ReadLine();  \n    }  \n  \n    // Put the shared speech recognizer into \"listening\" mode.  \n    static void  recognizer_StateChanged(object sender, StateChangedEventArgs e)  \n    {  \n     if (e.RecognizerState != RecognizerState.Stopped)  \n      {  \n        recognizer.EmulateRecognizeAsync(\"Start listening\");  \n      }  \n    }  \n  \n    // Write the text of the recognized phrase to the console.  \n    static void  recognizer_SpeechRecognized(object sender, SpeechRecognizedEventArgs e)  \n    {  \n     Console.WriteLine(\"Grammar({0}): {1}\", e.Result.Grammar.Name, e.Result.Text);  \n  \n      // Add event handler code here.  \n    }  \n  \n    // Handle the LoadGrammarCompleted event.  \n    static void  recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \n    {  \n     string grammarName = e.Grammar.Name;  \n      bool grammarLoaded = e.Grammar.Loaded;  \n      if (e.Error != null)  \n      {  \n        Console.WriteLine(\"LoadGrammar for {0} failed with a {1}.\",  \n        grammarName, e.Error.GetType().Name);  \n      }  \n  \n      // Add exception handling code here.  \n      Console.WriteLine(\"Grammar {0} {1} loaded.\",  \n      grammarName, (grammarLoaded) ? \"is\" : \"is not\");  \n    }  \n  }  \n}  \n  \n```"
  syntax:
    content: public event EventHandler<System.Speech.Recognition.StateChangedEventArgs> StateChanged;
    return:
      type: System.EventHandler{System.Speech.Recognition.StateChangedEventArgs}
      description: "要添加。"
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars
  id: UnloadAllGrammars
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: UnloadAllGrammars()
  nameWithType: SpeechRecognizer.UnloadAllGrammars()
  fullName: System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars()
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "卸载共享识别器从外的所有语音识别语法。"
  remarks: "如果识别器当前正在以异步方式加载语法，此方法等待，直到之前它卸载识别器的语法的所有加载语法。       若要卸载特定语法，请使用<xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A>方法。</xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A>"
  syntax:
    content: public void UnloadAllGrammars ();
    parameters: []
  overload: System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)
  id: UnloadGrammar(System.Speech.Recognition.Grammar)
  parent: System.Speech.Recognition.SpeechRecognizer
  langs:
  - csharp
  name: UnloadGrammar(Grammar)
  nameWithType: SpeechRecognizer.UnloadGrammar(Grammar)
  fullName: System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(Grammar)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "卸载共享识别器从指定的语言识别语法。"
  remarks: "如果识别器正在运行，应用程序必须使用<xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A>暂停之前加载、 卸载、 启用，或禁用语法的语音识别引擎。</xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A> 若要卸载的所有语法，请使用<xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A>方法。</xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A>"
  syntax:
    content: public void UnloadGrammar (System.Speech.Recognition.Grammar grammar);
    parameters:
    - id: grammar
      type: System.Speech.Recognition.Grammar
      description: "若要卸载语法。"
  overload: System.Speech.Recognition.SpeechRecognizer.UnloadGrammar*
  exceptions: []
  platform:
  - net462
references:
- uid: System.Object
  isExternal: false
  name: System.Object
- uid: System.Speech.Recognition.SpeechRecognizer.#ctor
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: SpeechRecognizer()
  nameWithType: SpeechRecognizer.SpeechRecognizer()
  fullName: System.Speech.Recognition.SpeechRecognizer.SpeechRecognizer()
- uid: System.Speech.Recognition.SpeechRecognizer.AudioFormat
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: AudioFormat
  nameWithType: SpeechRecognizer.AudioFormat
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioFormat
- uid: System.Speech.AudioFormat.SpeechAudioFormatInfo
  parent: System.Speech.AudioFormat
  isExternal: false
  name: SpeechAudioFormatInfo
  nameWithType: SpeechAudioFormatInfo
  fullName: System.Speech.AudioFormat.SpeechAudioFormatInfo
- uid: System.Speech.Recognition.SpeechRecognizer.AudioLevel
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: AudioLevel
  nameWithType: SpeechRecognizer.AudioLevel
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioLevel
- uid: System.Int32
  parent: System
  isExternal: true
  name: Int32
  nameWithType: Int32
  fullName: System.Int32
- uid: System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: AudioLevelUpdated
  nameWithType: SpeechRecognizer.AudioLevelUpdated
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated
- uid: System.EventHandler{System.Speech.Recognition.AudioLevelUpdatedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<AudioLevelUpdatedEventArgs>
  nameWithType: EventHandler<AudioLevelUpdatedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.AudioLevelUpdatedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.AudioLevelUpdatedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.AudioLevelUpdatedEventArgs
    name: AudioLevelUpdatedEventArgs
    nameWithType: AudioLevelUpdatedEventArgs
    fullName: AudioLevelUpdatedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognizer.AudioPosition
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: AudioPosition
  nameWithType: SpeechRecognizer.AudioPosition
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioPosition
- uid: System.TimeSpan
  parent: System
  isExternal: true
  name: TimeSpan
  nameWithType: TimeSpan
  fullName: System.TimeSpan
- uid: System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: AudioSignalProblemOccurred
  nameWithType: SpeechRecognizer.AudioSignalProblemOccurred
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred
- uid: System.EventHandler{System.Speech.Recognition.AudioSignalProblemOccurredEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<AudioSignalProblemOccurredEventArgs>
  nameWithType: EventHandler<AudioSignalProblemOccurredEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.AudioSignalProblemOccurredEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.AudioSignalProblemOccurredEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.AudioSignalProblemOccurredEventArgs
    name: AudioSignalProblemOccurredEventArgs
    nameWithType: AudioSignalProblemOccurredEventArgs
    fullName: AudioSignalProblemOccurredEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognizer.AudioState
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: AudioState
  nameWithType: SpeechRecognizer.AudioState
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioState
- uid: System.Speech.Recognition.AudioState
  parent: System.Speech.Recognition
  isExternal: false
  name: AudioState
  nameWithType: AudioState
  fullName: System.Speech.Recognition.AudioState
- uid: System.Speech.Recognition.SpeechRecognizer.AudioStateChanged
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: AudioStateChanged
  nameWithType: SpeechRecognizer.AudioStateChanged
  fullName: System.Speech.Recognition.SpeechRecognizer.AudioStateChanged
- uid: System.EventHandler{System.Speech.Recognition.AudioStateChangedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<AudioStateChangedEventArgs>
  nameWithType: EventHandler<AudioStateChangedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.AudioStateChangedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.AudioStateChangedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.AudioStateChangedEventArgs
    name: AudioStateChangedEventArgs
    nameWithType: AudioStateChangedEventArgs
    fullName: AudioStateChangedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognizer.Dispose
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: Dispose()
  nameWithType: SpeechRecognizer.Dispose()
  fullName: System.Speech.Recognition.SpeechRecognizer.Dispose()
- uid: System.Speech.Recognition.SpeechRecognizer.Dispose(System.Boolean)
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: Dispose(Boolean)
  nameWithType: SpeechRecognizer.Dispose(Boolean)
  fullName: System.Speech.Recognition.SpeechRecognizer.Dispose(Boolean)
- uid: System.Boolean
  parent: System
  isExternal: true
  name: Boolean
  nameWithType: Boolean
  fullName: System.Boolean
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String)
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: EmulateRecognize(String)
  nameWithType: SpeechRecognizer.EmulateRecognize(String)
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(String)
- uid: System.Speech.Recognition.RecognitionResult
  parent: System.Speech.Recognition
  isExternal: false
  name: RecognitionResult
  nameWithType: RecognitionResult
  fullName: System.Speech.Recognition.RecognitionResult
- uid: System.String
  parent: System
  isExternal: true
  name: String
  nameWithType: String
  fullName: System.String
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: EmulateRecognize(RecognizedWordUnit[],CompareOptions)
  nameWithType: SpeechRecognizer.EmulateRecognize(RecognizedWordUnit[],CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(RecognizedWordUnit[],CompareOptions)
- uid: System.Speech.Recognition.RecognizedWordUnit[]
  parent: System.Speech.Recognition
  isExternal: false
  name: RecognizedWordUnit
  nameWithType: RecognizedWordUnit
  fullName: System.Speech.Recognition.RecognizedWordUnit[]
  spec.csharp:
  - uid: System.Speech.Recognition.RecognizedWordUnit
    name: RecognizedWordUnit
    nameWithType: RecognizedWordUnit
    fullName: RecognizedWordUnit[]
  - name: '[]'
    nameWithType: '[]'
    fullName: '[]'
- uid: System.Globalization.CompareOptions
  parent: System.Globalization
  isExternal: true
  name: CompareOptions
  nameWithType: CompareOptions
  fullName: System.Globalization.CompareOptions
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(System.String,System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: EmulateRecognize(String,CompareOptions)
  nameWithType: SpeechRecognizer.EmulateRecognize(String,CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize(String,CompareOptions)
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String)
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: EmulateRecognizeAsync(String)
  nameWithType: SpeechRecognizer.EmulateRecognizeAsync(String)
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(String)
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.Speech.Recognition.RecognizedWordUnit[],System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: EmulateRecognizeAsync(RecognizedWordUnit[],CompareOptions)
  nameWithType: SpeechRecognizer.EmulateRecognizeAsync(RecognizedWordUnit[],CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(RecognizedWordUnit[],CompareOptions)
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(System.String,System.Globalization.CompareOptions)
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: EmulateRecognizeAsync(String,CompareOptions)
  nameWithType: SpeechRecognizer.EmulateRecognizeAsync(String,CompareOptions)
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync(String,CompareOptions)
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: EmulateRecognizeCompleted
  nameWithType: SpeechRecognizer.EmulateRecognizeCompleted
  fullName: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted
- uid: System.EventHandler{System.Speech.Recognition.EmulateRecognizeCompletedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<EmulateRecognizeCompletedEventArgs>
  nameWithType: EventHandler<EmulateRecognizeCompletedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.EmulateRecognizeCompletedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.EmulateRecognizeCompletedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.EmulateRecognizeCompletedEventArgs
    name: EmulateRecognizeCompletedEventArgs
    nameWithType: EmulateRecognizeCompletedEventArgs
    fullName: EmulateRecognizeCompletedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognizer.Enabled
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: Enabled
  nameWithType: SpeechRecognizer.Enabled
  fullName: System.Speech.Recognition.SpeechRecognizer.Enabled
- uid: System.Speech.Recognition.SpeechRecognizer.Grammars
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: Grammars
  nameWithType: SpeechRecognizer.Grammars
  fullName: System.Speech.Recognition.SpeechRecognizer.Grammars
- uid: System.Collections.ObjectModel.ReadOnlyCollection{System.Speech.Recognition.Grammar}
  parent: System.Collections.ObjectModel
  isExternal: true
  name: ReadOnlyCollection<Grammar>
  nameWithType: ReadOnlyCollection<Grammar>
  fullName: System.Collections.ObjectModel.ReadOnlyCollection<System.Speech.Recognition.Grammar>
  spec.csharp:
  - uid: System.Collections.ObjectModel.ReadOnlyCollection`1
    name: ReadOnlyCollection
    nameWithType: ReadOnlyCollection
    fullName: ReadOnlyCollection<System.Speech.Recognition.Grammar>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.Grammar
    name: Grammar
    nameWithType: Grammar
    fullName: Grammar
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognizer.LoadGrammar(System.Speech.Recognition.Grammar)
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: LoadGrammar(Grammar)
  nameWithType: SpeechRecognizer.LoadGrammar(Grammar)
  fullName: System.Speech.Recognition.SpeechRecognizer.LoadGrammar(Grammar)
- uid: System.Speech.Recognition.Grammar
  parent: System.Speech.Recognition
  isExternal: false
  name: Grammar
  nameWithType: Grammar
  fullName: System.Speech.Recognition.Grammar
- uid: System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(System.Speech.Recognition.Grammar)
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: LoadGrammarAsync(Grammar)
  nameWithType: SpeechRecognizer.LoadGrammarAsync(Grammar)
  fullName: System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync(Grammar)
- uid: System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: LoadGrammarCompleted
  nameWithType: SpeechRecognizer.LoadGrammarCompleted
  fullName: System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted
- uid: System.EventHandler{System.Speech.Recognition.LoadGrammarCompletedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<LoadGrammarCompletedEventArgs>
  nameWithType: EventHandler<LoadGrammarCompletedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.LoadGrammarCompletedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.LoadGrammarCompletedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.LoadGrammarCompletedEventArgs
    name: LoadGrammarCompletedEventArgs
    nameWithType: LoadGrammarCompletedEventArgs
    fullName: LoadGrammarCompletedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognizer.MaxAlternates
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: MaxAlternates
  nameWithType: SpeechRecognizer.MaxAlternates
  fullName: System.Speech.Recognition.SpeechRecognizer.MaxAlternates
- uid: System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: PauseRecognizerOnRecognition
  nameWithType: SpeechRecognizer.PauseRecognizerOnRecognition
  fullName: System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition
- uid: System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: RecognizerAudioPosition
  nameWithType: SpeechRecognizer.RecognizerAudioPosition
  fullName: System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition
- uid: System.Speech.Recognition.SpeechRecognizer.RecognizerInfo
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: RecognizerInfo
  nameWithType: SpeechRecognizer.RecognizerInfo
  fullName: System.Speech.Recognition.SpeechRecognizer.RecognizerInfo
- uid: System.Speech.Recognition.RecognizerInfo
  parent: System.Speech.Recognition
  isExternal: false
  name: RecognizerInfo
  nameWithType: RecognizerInfo
  fullName: System.Speech.Recognition.RecognizerInfo
- uid: System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: RecognizerUpdateReached
  nameWithType: SpeechRecognizer.RecognizerUpdateReached
  fullName: System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached
- uid: System.EventHandler{System.Speech.Recognition.RecognizerUpdateReachedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<RecognizerUpdateReachedEventArgs>
  nameWithType: EventHandler<RecognizerUpdateReachedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.RecognizerUpdateReachedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.RecognizerUpdateReachedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.RecognizerUpdateReachedEventArgs
    name: RecognizerUpdateReachedEventArgs
    nameWithType: RecognizerUpdateReachedEventArgs
    fullName: RecognizerUpdateReachedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: RequestRecognizerUpdate()
  nameWithType: SpeechRecognizer.RequestRecognizerUpdate()
  fullName: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate()
- uid: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object)
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: RequestRecognizerUpdate(Object)
  nameWithType: SpeechRecognizer.RequestRecognizerUpdate(Object)
  fullName: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(Object)
- uid: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(System.Object,System.TimeSpan)
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: RequestRecognizerUpdate(Object,TimeSpan)
  nameWithType: SpeechRecognizer.RequestRecognizerUpdate(Object,TimeSpan)
  fullName: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate(Object,TimeSpan)
- uid: System.Speech.Recognition.SpeechRecognizer.SpeechDetected
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: SpeechDetected
  nameWithType: SpeechRecognizer.SpeechDetected
  fullName: System.Speech.Recognition.SpeechRecognizer.SpeechDetected
- uid: System.EventHandler{System.Speech.Recognition.SpeechDetectedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<SpeechDetectedEventArgs>
  nameWithType: EventHandler<SpeechDetectedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.SpeechDetectedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.SpeechDetectedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.SpeechDetectedEventArgs
    name: SpeechDetectedEventArgs
    nameWithType: SpeechDetectedEventArgs
    fullName: SpeechDetectedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: SpeechHypothesized
  nameWithType: SpeechRecognizer.SpeechHypothesized
  fullName: System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized
- uid: System.EventHandler{System.Speech.Recognition.SpeechHypothesizedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<SpeechHypothesizedEventArgs>
  nameWithType: EventHandler<SpeechHypothesizedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.SpeechHypothesizedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.SpeechHypothesizedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.SpeechHypothesizedEventArgs
    name: SpeechHypothesizedEventArgs
    nameWithType: SpeechHypothesizedEventArgs
    fullName: SpeechHypothesizedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: SpeechRecognitionRejected
  nameWithType: SpeechRecognizer.SpeechRecognitionRejected
  fullName: System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected
- uid: System.EventHandler{System.Speech.Recognition.SpeechRecognitionRejectedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<SpeechRecognitionRejectedEventArgs>
  nameWithType: EventHandler<SpeechRecognitionRejectedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.SpeechRecognitionRejectedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.SpeechRecognitionRejectedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.SpeechRecognitionRejectedEventArgs
    name: SpeechRecognitionRejectedEventArgs
    nameWithType: SpeechRecognitionRejectedEventArgs
    fullName: SpeechRecognitionRejectedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognizer.SpeechRecognized
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: SpeechRecognized
  nameWithType: SpeechRecognizer.SpeechRecognized
  fullName: System.Speech.Recognition.SpeechRecognizer.SpeechRecognized
- uid: System.EventHandler{System.Speech.Recognition.SpeechRecognizedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<SpeechRecognizedEventArgs>
  nameWithType: EventHandler<SpeechRecognizedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.SpeechRecognizedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.SpeechRecognizedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.SpeechRecognizedEventArgs
    name: SpeechRecognizedEventArgs
    nameWithType: SpeechRecognizedEventArgs
    fullName: SpeechRecognizedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognizer.State
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: State
  nameWithType: SpeechRecognizer.State
  fullName: System.Speech.Recognition.SpeechRecognizer.State
- uid: System.Speech.Recognition.RecognizerState
  parent: System.Speech.Recognition
  isExternal: false
  name: RecognizerState
  nameWithType: RecognizerState
  fullName: System.Speech.Recognition.RecognizerState
- uid: System.Speech.Recognition.SpeechRecognizer.StateChanged
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: StateChanged
  nameWithType: SpeechRecognizer.StateChanged
  fullName: System.Speech.Recognition.SpeechRecognizer.StateChanged
- uid: System.EventHandler{System.Speech.Recognition.StateChangedEventArgs}
  parent: System
  isExternal: true
  name: EventHandler<StateChangedEventArgs>
  nameWithType: EventHandler<StateChangedEventArgs>
  fullName: System.EventHandler<System.Speech.Recognition.StateChangedEventArgs>
  spec.csharp:
  - uid: System.EventHandler`1
    name: EventHandler
    nameWithType: EventHandler
    fullName: EventHandler<System.Speech.Recognition.StateChangedEventArgs>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.StateChangedEventArgs
    name: StateChangedEventArgs
    nameWithType: StateChangedEventArgs
    fullName: StateChangedEventArgs
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: UnloadAllGrammars()
  nameWithType: SpeechRecognizer.UnloadAllGrammars()
  fullName: System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars()
- uid: System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(System.Speech.Recognition.Grammar)
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: UnloadGrammar(Grammar)
  nameWithType: SpeechRecognizer.UnloadGrammar(Grammar)
  fullName: System.Speech.Recognition.SpeechRecognizer.UnloadGrammar(Grammar)
- uid: System.Speech.Recognition.SpeechRecognizer.#ctor*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: SpeechRecognizer
  nameWithType: SpeechRecognizer.SpeechRecognizer
- uid: System.Speech.Recognition.SpeechRecognizer.AudioFormat*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: AudioFormat
  nameWithType: SpeechRecognizer.AudioFormat
- uid: System.Speech.Recognition.SpeechRecognizer.AudioLevel*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: AudioLevel
  nameWithType: SpeechRecognizer.AudioLevel
- uid: System.Speech.Recognition.SpeechRecognizer.AudioPosition*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: AudioPosition
  nameWithType: SpeechRecognizer.AudioPosition
- uid: System.Speech.Recognition.SpeechRecognizer.AudioState*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: AudioState
  nameWithType: SpeechRecognizer.AudioState
- uid: System.Speech.Recognition.SpeechRecognizer.Dispose*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: Dispose
  nameWithType: SpeechRecognizer.Dispose
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognize*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: EmulateRecognize
  nameWithType: SpeechRecognizer.EmulateRecognize
- uid: System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: EmulateRecognizeAsync
  nameWithType: SpeechRecognizer.EmulateRecognizeAsync
- uid: System.Speech.Recognition.SpeechRecognizer.Enabled*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: Enabled
  nameWithType: SpeechRecognizer.Enabled
- uid: System.Speech.Recognition.SpeechRecognizer.Grammars*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: Grammars
  nameWithType: SpeechRecognizer.Grammars
- uid: System.Speech.Recognition.SpeechRecognizer.LoadGrammar*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: LoadGrammar
  nameWithType: SpeechRecognizer.LoadGrammar
- uid: System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: LoadGrammarAsync
  nameWithType: SpeechRecognizer.LoadGrammarAsync
- uid: System.Speech.Recognition.SpeechRecognizer.MaxAlternates*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: MaxAlternates
  nameWithType: SpeechRecognizer.MaxAlternates
- uid: System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: PauseRecognizerOnRecognition
  nameWithType: SpeechRecognizer.PauseRecognizerOnRecognition
- uid: System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: RecognizerAudioPosition
  nameWithType: SpeechRecognizer.RecognizerAudioPosition
- uid: System.Speech.Recognition.SpeechRecognizer.RecognizerInfo*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: RecognizerInfo
  nameWithType: SpeechRecognizer.RecognizerInfo
- uid: System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: RequestRecognizerUpdate
  nameWithType: SpeechRecognizer.RequestRecognizerUpdate
- uid: System.Speech.Recognition.SpeechRecognizer.State*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: State
  nameWithType: SpeechRecognizer.State
- uid: System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: UnloadAllGrammars
  nameWithType: SpeechRecognizer.UnloadAllGrammars
- uid: System.Speech.Recognition.SpeechRecognizer.UnloadGrammar*
  parent: System.Speech.Recognition.SpeechRecognizer
  isExternal: false
  name: UnloadGrammar
  nameWithType: SpeechRecognizer.UnloadGrammar
